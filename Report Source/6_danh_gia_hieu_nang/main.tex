\chapter{Ước lượng hiệu năng}
\label{ch:evaluation}

Chương này trình bày các kết quả thực nghiệm thu được từ mô hình ước lượng hiệu năng của kiến trúc phần cứng được đề xuất trong đồ án. Nội dung đánh giá tập trung vào việc phân tích hiệu quả của thuật toán tối ưu tham số (Codegen) và khả năng xử lý của phần cứng đối với ba lớp mô hình đại diện gồm AlexNet, VGG-16 và MobileNetV1. Bên cạnh đó, nhóm thực hiện cũng tiến hành so sánh kết quả với kiến trúc Eyeriss để làm rõ các ưu điểm và hạn chế của giải pháp thiết kế.

\section{Môi trường và Phương pháp thực nghiệm}

Nhằm đánh giá để tiên liệu trước về hiệu năng của đồ án này, kiến trúc được đánh giá thông qua một mô hình ước lượng (Analytical Estimator) xây dựng bằng ngôn ngữ C++. Mô hình này hiện thực hóa các công thức toán học đã được thiết lập tại Chương 4 nhằm dự báo độ trễ và tài nguyên tiêu thụ.

Các tham số cấu hình cho quá trình mô phỏng được thiết lập dựa trên các ràng buộc phần cứng dự kiến. Cụ thể, hệ thống hoạt động ở tần số $200 \text{ MHz}$ với số lượng đơn vị xử lý (PEs) tiêu chuẩn là 385. Tốc độ của off-chip memory là 1 byte 1 cycle tương ứng tần số 200 MHz. Các giá trị đã được quantized ở dạng int8.Phạm vi đánh giá chỉ tập trung đo đạc thời gian thực thi của các lớp tích chập (Convolutional Layers), vốn là thành phần chiếm tỷ trọng tính toán lớn nhất trong mạng CNN. Chiến lược xử lý được lựa chọn là Batch Size = 1 nhằm tối ưu hóa độ trễ cho tác vụ xử lý từng ảnh đơn lẻ. Về cấu hình bộ nhớ, đồ án giả lập kiến trúc bộ nhớ tách biệt (Separate Off-chip Memory), trong đó Trọng số (Weights) và Dữ liệu (Activations) được truy xuất trên các kênh độc lập để tối ưu băng thông.

\section{Đánh giá khả năng xử lý trên AlexNet}
\label{sec:alexnet_eval}

AlexNet là một mạng nơ-ron tích chập điển hình, được đặc trưng bởi việc sử dụng các bộ lọc kích thước lớn ở các lớp đầu tiên ($11\times11$, $5\times5$). Để đánh giá hiệu năng, đồ án thực hiện chạy quá trình sinh mã (codegen) nhằm phân tích mối tương quan giữa số lượng phần tử xử lý (PE) và thời gian hoàn thành mô hình. Kết quả phân tích được thể hiện qua biểu đồ dưới đây.

\begin{figure}[H]
    \centering
    % 
    % Thay thế 'alexnet_pe_chart.png' bằng tên file ảnh thực tế của bạn
    \includegraphics[width=0.8\textwidth]{image/6/alexnet_pe_chart.png}
    \caption{Biểu đồ tương quan giữa số lượng PE và độ trễ xử lý trên AlexNet}
    \label{fig:alexnet_chart}
\end{figure}

Quan sát biểu đồ tại Hình \ref{fig:alexnet_chart}, có thể thấy điểm tối ưu nhất đạt được tại cấu hình $PE = 572$ với độ trễ (latency) là $15.05$ ms, tương đương tốc độ khung hình $66.44$ fps. Nguyên nhân là khi tăng số lượng PE, số lượng các kênh bản đồ đặc trưng đầu ra (ofmap) được tính toán song song sẽ tăng lên, đồng nghĩa với việc số lần phải tải lại toàn bộ bản đồ đặc trưng đầu vào (ifmap) giảm xuống. Với các giá trị $T_m$ tăng dần, thời gian xử lý giảm xuống rất nhanh. Tuy nhiên, khi chênh lệch giữa thời gian tải ifmap và thời gian tải ofmap không còn đáng kể, tốc độ giảm của thời gian xử lý sẽ bắt đầu bão hòa và chậm dần. Kết quả mô phỏng chi tiết với giới hạn tài nguyên 572 PEs được trình bày tại Bảng \ref{tab:alexnet_breakdown}.

\begin{table}[H]
\centering
\caption{Chi tiết hiệu năng từng lớp của AlexNet}
\label{tab:alexnet_breakdown}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
\multirow{2}{*}{\textbf{Layer}} & \multirow{2}{*}{\textbf{Filter / Channels}} & \multirow{2}{*}{\textbf{Map Size}} & \multirow{2}{*}{\textbf{PE Used}} & \multicolumn{3}{c}{\textbf{Optimized Config}} & \multirow{2}{*}{\textbf{Latency (ms)}} & \multirow{2}{*}{\textbf{Bottleneck}} \\ \cmidrule(lr){5-7}
 &  &  &  & $\mathbf{T_k}$ & $\mathbf{T_m}$ & $\mathbf{T_h}$ &  &  \\ \midrule
Conv1 & $11\times11 / 96$ & $224 \times 224$ & 528 & 1 & 48 & 1 & 5.23 & Memory \\
Conv2 & $5\times5 / 256$ & $27 \times 27$ & 520 & 1 & 52 & 1 & 3.00 & Memory \\
Conv3 & $3\times3 / 384$ & $13 \times 13$ & 432 & 1 & 48 & 1 & 2.06 & Memory \\
Conv4 & $3\times3 / 384$ & $13 \times 13$ & 432 & 1 & 48 & 1 & 2.92 & Memory \\
Conv5 & $3\times3 / 256$ & $13 \times 13$ & 468 & 1 & 52 & 1 & 1.84 & Memory \\ \midrule
\textbf{Total} & \textbf{--} & \textbf{--} & \textbf{Max 528} & \textbf{--} & \textbf{--} & \textbf{--} & \textbf{15.05} & \textbf{Memory} \\ \bottomrule
\end{tabular}%
}
\end{table}

Dựa trên kết quả thực nghiệm được trình bày tại Bảng \ref{tab:alexnet_breakdown}, nhóm em có những phân tích cụ thể về hiệu năng của mô hình AlexNet với tổng thời gian thực thi là $15.05$ ms như sau:

Trước hết, về mặt phân bổ tài nguyên phần cứng, hệ thống vận hành với cấu hình sử dụng tối đa $572$ PE. Các lớp từ Conv1 đến Conv5 cho thấy sự điều chỉnh linh hoạt trong việc sử dụng số lượng PE, dao động từ $432$ đến $528$ đơn vị. Việc duy trì số lượng PE ở mức cao kết hợp với các tham số tối ưu hóa $T_m$ (lên đến $52$) và $T_h$ cho thấy nỗ lực của hệ thống trong việc song song hóa các phép tính tích chập trên toàn bộ mô hình.

Tuy nhiên, đặc điểm nổi bật nhất trong kết quả thực nghiệm này là toàn bộ hệ thống đang vận hành trong trạng thái \textit{Memory Bound} (nghẽn bộ nhớ). Mặc dù các lớp có sự khác biệt lớn về kích thước bộ lọc từ $11 \times 11$ ở Conv1 xuống $3 \times 3$ ở các lớp sau nhưng điểm nghẽn về bộ nhớ vẫn duy trì xuyên suốt. Điều này cho thấy tốc độ truy xuất và cung cấp dữ liệu hiện tại chưa đáp ứng kịp năng lực xử lý của mảng PE, khiến thời gian thực thi bị chi phối bởi băng thông lưu trữ. Trong đó, lớp Conv1 chiếm tỷ trọng thời gian lớn nhất ($5.23$ ms), tương ứng với kích thước bộ lọc lớn nhất, đặt ra áp lực nặng nề nhất lên hệ thống lưu trữ.

Tổng kết lại, với mức tổng độ trễ $15.05$ ms, mô hình đang gặp giới hạn tại băng thông bộ nhớ. Để cải thiện hiệu năng trong các bước tiếp theo, các giải pháp cần hướng tới việc tối ưu hóa khả năng tái sử dụng dữ liệu hoặc cải thiện tốc độ truy xuất của hệ thống bộ nhớ đệm nhằm giải tỏa điểm nghẽn hiện tại cho mảng PE đã thiết lập.
\section{Đánh giá khả năng xử lý trên VGG-16}
\label{sec:vgg_eval}

Để kiểm chứng khả năng chịu tải của hệ thống đối với các mạng nơ-ron tích chập có độ sâu lớn, đồ án thực hiện mô phỏng trên mô hình VGG-16. Quá trình sinh mã và phân tích sự tương quan giữa số lượng PE và thời gian hoàn thành mô hình cho kết quả như biểu đồ sau.

\begin{figure}[H]
    \centering
    % 
    % Thay thế 'vgg16_pe_chart.png' bằng tên file ảnh thực tế của bạn
    \includegraphics[width=0.8\textwidth]{image/6/vgg16_pe_chart.png}
    \caption{Biểu đồ tương quan giữa số lượng PE và độ trễ xử lý trên VGG-16}
    \label{fig:vgg16_chart}
\end{figure}

Dựa vào biểu đồ Hình \ref{fig:vgg16_chart}, điểm tối ưu nhất được xác định tại $PE = 384$ với độ trễ đạt $210.63$ ms, tương đương $4.75$ fps. Tương tự như AlexNet, việc tăng số lượng PE giúp tăng số kênh ofmap được tính toán song song và giảm số lần tải lại ifmap. Tuy nhiên, khi độ trễ giữa các lần truy cập bộ nhớ giảm xuống đến mức bão hòa, đường cong hiệu năng cũng dần đi ngang. Kết quả mô phỏng chi tiết trên tập cấu hình phần cứng tối ưu với giới hạn 390 PEs được trình bày tại Bảng \ref{tab:vgg16_breakdown}.

\begin{table}[H]
\centering
\caption{Chi tiết hiệu năng từng lớp của VGG-16}
\label{tab:vgg16_breakdown}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
\multirow{2}{*}{\textbf{Layer}} & \multirow{2}{*}{\textbf{Filter / Channels}} & \multirow{2}{*}{\textbf{Map Size}} & \multirow{2}{*}{\textbf{PE Used}} & \multicolumn{3}{c}{\textbf{Optimized Config}} & \multirow{2}{*}{\textbf{Latency (ms)}} & \multirow{2}{*}{\textbf{Bottleneck}} \\ \cmidrule(lr){5-7}
 & & & & $\mathbf{T_k}$ & $\mathbf{T_m}$ & $\mathbf{T_h}$ & & \\ \midrule
Conv1\_1 & $3\times3 / 64$ & $224 \times 224$ & 384 & 2 & 64 & 1 & 16.98 & Memory \\
Conv1\_2 & $3\times3 / 64$ & $224 \times 224$ & 384 & 2 & 64 & 1 & 37.39 & Memory \\
Conv2\_1 & $3\times3 / 128$ & $112 \times 112$ & 384 & 2 & 64 & 1 & 17.45 & Memory \\
Conv2\_2 & $3\times3 / 128$ & $112 \times 112$ & 384 & 2 & 64 & 1 & 26.91 & Memory \\
Conv3\_1 & $3\times3 / 256$ & $56 \times 56$ & 384 & 2 & 64 & 1 & 12.04 & Memory \\
Conv3\_2 & $3\times3 / 256$ & $56 \times 56$ & 384 & 2 & 64 & 1 & 20.07 & Memory \\
Conv3\_3 & $3\times3 / 256$ & $56 \times 56$ & 384 & 2 & 64 & 1 & 20.07 & Memory \\
Conv4\_1 & $3\times3 / 512$ & $28 \times 28$ & 384 & 2 & 64 & 1 & 10.04 & Memory \\
Conv4\_2 & $3\times3 / 512$ & $28 \times 28$ & 384 & 2 & 64 & 1 & 18.06 & Memory \\
Conv4\_3 & $3\times3 / 512$ & $28 \times 28$ & 384 & 2 & 64 & 1 & 18.06 & Memory \\
Conv5\_1 & $3\times3 / 512$ & $14 \times 14$ & 192 & 1 & 64 & 1 & 4.52 & Memory \\
Conv5\_2 & $3\times3 / 512$ & $14 \times 14$ & 192 & 1 & 64 & 1 & 4.52 & Memory \\
Conv5\_3 & $3\times3 / 512$ & $14 \times 14$ & 192 & 1 & 64 & 1 & 4.52 & Memory \\ \midrule
\textbf{Total} & \textbf{--} & \textbf{--} & \textbf{384} & \textbf{--} & \textbf{--} & \textbf{--} & \textbf{210.63} & \textbf{Memory} \\ \bottomrule
\end{tabular}%
}
\end{table}

Kết quả mô phỏng thực tế đã xác nhận tính hiệu quả của chiến lược phân bổ tài nguyên phần cứng đối với mô hình VGG-16, với tổng thời gian thực thi đạt mức \textbf{210.63 ms}. Hệ thống duy trì mức huy động tài nguyên tối đa là \textbf{384 PEs} cho phần lớn các lớp thông qua việc áp dụng cấu hình song song hóa $(T_k=2, T_m=64, T_h=1)$. Đáng chú ý, tại các lớp thuộc khối Conv5, số lượng PE sử dụng được điều chỉnh xuống còn \textbf{192 PEs} do tham số $T_k$ giảm xuống bằng 1, minh chứng cho khả năng tự động tối ưu hóa việc phân bổ tài nguyên dựa trên sự thay đổi về số lượng kênh và kích thước bản đồ đặc trưng ở các tầng sâu.

Dựa trên số liệu thống kê về điểm nghẽn hệ thống (Bottleneck), toàn bộ 13 lớp tích chập từ Conv1\_1 đến Conv5\_3 đều được xác định ở trạng thái giới hạn bởi bộ nhớ (\textit{Memory bound}).

 Các kết quả đo đạc cho thấy việc gia tăng số lượng PE đơn thuần sẽ không mang lại hiệu quả vượt trội nếu không đi kèm với các cải tiến về băng thông bộ nhớ hoặc tối ưu hóa sơ đồ truy xuất dữ liệu bản đồ kênh đầu vào ($ifmap$). Do đó, các hướng phát triển tiếp theo nên tập trung vào việc giảm thiểu trạng thái chờ của đơn vị xử lý thông qua các kỹ thuật quản lý bộ nhớ đệm hoặc tối ưu hóa luồng dữ liệu để giải quyết triệt để tình trạng nghẽn mạch tại các lớp có kích thước dữ liệu lớn.

\section{Đánh giá khả năng xử lý trên MobileNet v1}
\label{sec:mobilenet_eval}

Khác với VGG-16, MobileNet v1 sử dụng kiến trúc tích chập tách biệt theo chiều sâu (Depthwise Separable Convolution) nhằm giảm khối lượng tính toán. Đồ án tiến hành chạy codegen để phân tích sự tương quan giữa số lượng PE và thời gian hoàn thành mô hình, kết quả được thể hiện trong biểu đồ sau.

\begin{figure}[H]
    \centering
    % 
    % Thay thế 'mobilenet_pe_chart.png' bằng tên file ảnh thực tế của bạn
    \includegraphics[width=0.8\textwidth]{image/6/mobilenet_pe_chart.png}
    \caption{Biểu đồ tương quan giữa số lượng PE và độ trễ xử lý trên MobileNet v1}
    \label{fig:mobilenet_chart}
\end{figure}

Dựa trên biểu đồ Hình \ref{fig:mobilenet_chart}, điểm tối ưu nhất đạt được tại $PE = 399$ với độ trễ $60.35$ ms, tương đương $16.5$ fps. Tốc độ giảm của thời gian hoàn thành khi tăng số PE chậm hơn rất nhiều so với biểu đồ của AlexNet. Lý do chính là hệ thống không vận dụng được cơ chế tích luỹ theo chiều sâu, vốn là điểm mạnh của mô hình tại các lớp Depthwise Convolution. Điều này dẫn tới thời gian xử lý không giảm đáng kể ở các lớp này, mà chủ yếu chỉ được cải thiện ở các lớp Pointwise Convolution và Standard Convolution. Kết quả mô phỏng trên tập cấu hình phần cứng tối ưu với giới hạn 385 PEs được trình bày tại Bảng \ref{tab:mobilenet_breakdown}.
\begin{table}[H]
\centering
\caption{Hiệu năng chi tiết từng lớp của MobileNet v1}
\label{tab:mobilenet_breakdown}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
\multirow{2}{*}{\textbf{Layer}} & \multirow{2}{*}{\textbf{Filter / Channels}} & \multirow{2}{*}{\textbf{Map Size}} & \multirow{2}{*}{\textbf{PE Used}} & \multicolumn{3}{c}{\textbf{Optimized Config}} & \multirow{2}{*}{\textbf{Latency (ms)}} & \multirow{2}{*}{\textbf{Bottleneck}} \\ \cmidrule(lr){5-7}
 &  &  &  & $\mathbf{T_k}$ & $\mathbf{T_m}$ & $\mathbf{T_h}$ &  &  \\ \midrule
Standard Conv & $3\times3 / 32$ & $224 \times 224$ & 96 & 1 & 32 & 1 & 3.18 & Memory \\ \midrule
Depthwise 1 & $3\times3 / 32$ & $112 \times 112$ & 96 & 1 & 32 & 18 & 3.72 & Memory \\
Pointwise 2 & $1\times1 / 64$ & $112 \times 112$ & 192 & 1 & 64 & 1 & 6.02 & Memory \\ \midrule
Depthwise 3 & $3\times3 / 64$ & $56 \times 56$ & 192 & 1 & 64 & 18 & 4.87 & Memory \\
Pointwise 4 & $1\times1 / 128$ & $56 \times 56$ & 384 & 1 & 128 & 1 & 3.01 & Memory \\ \midrule
Depthwise 5 & $3\times3 / 128$ & $56 \times 56$ & 384 & 1 & 128 & 36 & 2.74 & Memory \\
Pointwise 6 & $1\times1 / 128$ & $56 \times 56$ & 384 & 1 & 128 & 1 & 4.01 & Memory \\ \midrule
Depthwise 7 & $3\times3 / 128$ & $28 \times 28$ & 384 & 1 & 128 & 36 & 2.20 & Memory \\
Pointwise 8 & $1\times1 / 256$ & $28 \times 28$ & 384 & 1 & 128 & 1 & 2.01 & Memory \\ \midrule
Depthwise 9 & $3\times3 / 256$ & $28 \times 28$ & 399 & 1 & 133 & 28 & 1.49 & Memory \\
Pointwise 10 & $1\times1 / 256$ & $28 \times 28$ & 384 & 1 & 128 & 1 & 3.01 & Memory \\ \midrule
Depthwise 11 & $3\times3 / 256$ & $14 \times 14$ & 399 & 1 & 133 & 28 & 1.13 & Memory \\
Pointwise 12 & $1\times1 / 512$ & $14 \times 14$ & 384 & 1 & 128 & 1 & 1.51 & Memory \\ \midrule
Total Pointwise & $1\times1 / 512$ & $14 \times 14$ & 384 & 1 & 128 & 1 & 12.55 & Memory \\
Total Depthwise & $3\times3 / 512$ & $14 \times 14$ & 399 & 1 & 133 & 14 & 3.48 & Memory \\ \midrule
\textbf{Total} & \textbf{--} & \textbf{--} & \textbf{Max 399} & \textbf{--} & \textbf{--} & \textbf{--} & \textbf{60.35} & \textbf{Memory} \\ \bottomrule
\end{tabular}%
}
\end{table}
Dựa trên kết quả ước lượng tại Bảng \ref{tab:mobilenet_breakdown}, tổng thời gian thực thi (Total Latency) của mô hình MobileNet v1 đạt $60.35$ ms với cấu hình phần cứng tối đa $399$ PE. Đặc điểm quan trọng nhất được ghi nhận là trạng thái giới hạn hiệu năng đồng nhất trên toàn bộ kiến trúc mạng, trong đó $100\%$ các lớp từ Standard Conv, Depthwise đến Pointwise đều ở tình trạng nghẽn bộ nhớ (Memory Bound). Điều này khẳng định rằng tại cấu hình tối ưu của các tham số $T_k, T_m, T_h$, tốc độ tính toán lý thuyết của mảng PE đã vượt ngưỡng đáp ứng của băng thông bộ nhớ, khiến thời gian truy xuất dữ liệu trở thành yếu tố quyết định độ trễ.

Trong các lớp Pointwise ($1 \times 1$ Conv), hệ thống duy trì cấu hình ổn định chủ đạo với $T_k = 1, T_m = 128$ và $T_h = 1$, huy động $384$ PE cho mỗi chu kỳ tính toán (ngoại trừ Layer 2 sử dụng $192$ PE). Mặc dù năng lực tính toán được huy động ở mức cao, các lớp Pointwise vẫn chiếm tỷ trọng thời gian đáng kể, dao động từ $1.25$ ms đến $6.02$ ms. Sự biến thiên độ trễ này tỉ lệ thuận với kích thước bản đồ đặc trưng (Feature Map), cho thấy áp lực lên băng thông bộ nhớ tăng cao khi khối lượng dữ liệu đầu vào lớn dù năng lực tính toán tại chỗ được giữ ở mức cao và cố định.

Đối với các lớp Depthwise ($3 \times 3$ DW), bảng số liệu cho thấy một chiến lược phân bổ tài nguyên linh hoạt nhằm tối ưu hóa hiệu năng. Số lượng PE được huy động tăng dần từ $96$ PE (tại Layer 1) lên mức tối đa $399$ PE (từ Layer 9 đến Layer 25) thông qua việc điều chỉnh tham số $T_m$ lên mức cực đại là $133$. Song song với đó, tham số $T_h$ được điều chỉnh giảm dần theo chiều sâu của mạng, từ $36$ xuống còn $7$ tại lớp cuối cùng. Kết quả của chiến lược này là sự sụt giảm mạnh mẽ về độ trễ của các lớp Depthwise, đạt mức tối thiểu $0.47$ ms tại Layer 25. Sự kết hợp giữa việc tăng cường tối đa số lượng PE xử lý ($399$ PE) và tối ưu hóa kích thước khối dữ liệu $T_h$ cho thấy hệ thống đã tận dụng tối đa khả năng song song hóa để giảm thiểu tác động của trễ truy xuất bộ nhớ lên tổng thời gian thực thi.
\section{So sánh với các Nghiên cứu liên quan}
\label{sec:comparison}

Để đánh giá khách quan hiệu quả của kiến trúc đề xuất, chúng tôi thực hiện so sánh đối chứng với kết quả đo đạc thực tế trên silicon của chip gia tốc Eyeriss [Chen et al., ISSCC 2016]. Các thông số tham chiếu của Eyeriss được lấy từ cấu hình tối ưu với Batch Size $N=4$ cho AlexNet và $N=3$ cho VGG16.Nhằm đảm bảo tính tương đồng trong điều kiện thử nghiệm, kiến trúc đề xuất được cấu hình với 165 PE (xấp xỉ số lượng PE của Eyeriss), đồng thời sử dụng mô hình AlexNet với Grouped Convolution tại các lớp conv2, conv4 và conv5 đúng theo nguyên bản. Bên cạnh đó, các tham số hệ thống cũng được đồng bộ hóa với thiết kế Eyeriss: băng thông bộ nhớ ngoài (off-chip memory) giới hạn ở mức 480MB/s và độ chính xác tính toán là 16-bit fixed-point. Kết quả so sánh chi tiết được trình bày tại Bảng \ref{tab:comparison_eyeriss}.

\begin{table}[H]
\centering
\caption{So sánh hiệu năng xử lý Convolution trên AlexNet và VGG16}
\label{tab:comparison_eyeriss}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|c|c|}
\hline
\textbf{Thông số} & \textbf{Đề xuất (Ours)} & \textbf{Eyeriss [Chen et al.]} \\ \hline
Số lượng PE & 165 (AlexNet) - 162 (VGG16) & 168 \\ \hline
Kiến trúc bộ nhớ & Separate Off-chip Memory & Shared DRAM \\ \hline
Chiến lược xử lý & \textbf{Batch Size = 1} (Real-time) & \textbf{Batch Size = 3-4} (Throughput) \\ \hline
\textbf{AlexNet (Latency)} & 31.02 ms (32.24 fps) & \textbf{28.57 ms}* (35.0 fps) \\ \hline
\textbf{VGG16 (Latency)} & \textbf{398.27 ms} (2.51 fps) & 1428.57 ms** (0.7 fps) \\ \hline
\end{tabular}%
}
\vspace{0.2cm}
\footnotesize{
\textit{*AlexNet Eyeriss: Tính trung bình trên Batch=4 ($N=4$).} \\
\textit{**VGG16 Eyeriss: Tính trung bình trên Batch=3 ($N=3$).}
}
\end{table}

Kết quả so sánh cho thấy hai xu hướng đối lập tương ứng với độ phức tạp của mạng nơ-ron:

\begin{itemize}
    \item \textbf{Đối với VGG16 (Mạng sâu và nặng):} Kiến trúc đề xuất đạt hiệu năng vượt trội với độ trễ thấp hơn khoảng \textbf{3.59 lần} so với Eyeriss (398.27 ms so với 1428.57 ms). Kết quả này đạt được nhờ chiến lược bộ nhớ tách biệt (Separate Off-chip Memory) giúp tăng băng thông truy xuất dữ liệu, giảm thiểu tình trạng nghẽn mạch (Memory Bottleneck) thường gặp ở các kiến trúc sử dụng bộ nhớ chia sẻ (Shared DRAM) như Eyeriss. Điều này đặc biệt quan trọng đối với các mạng nặng như VGG16, nơi khối lượng dữ liệu lớn đòi hỏi băng thông cao để duy trì hiệu năng tính toán.
    
    \item \textbf{Đối với AlexNet (Mạng nông, có Grouped Convolution):} Eyeriss giữ lợi thế về thông lượng (35 fps) nhờ cơ chế xử lý theo lô ($N=4$) và kiến trúc luồng dữ liệu (Dataflow) đặc thù giúp xử lý hiệu quả việc phân chia nhóm kênh. Tuy nhiên, giải pháp đề xuất ($N=1$) vẫn đạt độ trễ xấp xỉ 31 ms. Đây là kết quả khả quan, cung cấp khả năng phản hồi thời gian thực (Real-time) tốt hơn cho các ứng dụng đơn lẻ, loại bỏ được độ trễ tích lũy (batching latency) mà cơ chế xử lý theo lô của Eyeriss gặp phải.
\end{itemize}