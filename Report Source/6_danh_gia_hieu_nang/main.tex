\chapter{Ước lượng hiệu năng}
\label{ch:evaluation}

Chương này trình bày các kết quả thu được từ mô hình ước lượng hiệu năng của kiến trúc phần cứng AI Accelerator được đề xuất trong đồ án. Nội dung đánh giá tập trung vào việc phân tích hiệu quả của thuật toán tối ưu tham số (Codegen) và khả năng xử lý của phần cứng đối với ba lớp mô hình đại diện gồm AlexNet, VGG-16 và MobileNetV1. Bên cạnh đó, nhóm thực hiện cũng tiến hành so sánh kết quả với kiến trúc Eyeriss để làm rõ các ưu điểm và hạn chế của giải pháp thiết kế.

\section{Môi trường và Phương pháp thực nghiệm}

Nhằm đánh giá để tiên liệu trước về hiệu năng của đồ án này, kiến trúc được đánh giá thông qua một mô hình ước lượng (Analytical Estimator) xây dựng bằng ngôn ngữ C++. Mô hình này hiện thực hóa các công thức toán học đã được thiết lập tại Chương 4 nhằm dự báo độ trễ và tài nguyên tiêu thụ.

Các tham số cấu hình cho quá trình mô phỏng được thiết lập dựa trên các ràng buộc phần cứng dự kiến. Cụ thể, hệ thống hoạt động ở tần số $200 \text{ MHz}$. Tốc độ của off-chip memory là 1 byte 1 cycle tương ứng tần số 200 MHz. Các giá trị đã được quantized ở dạng int8. Phạm vi đánh giá chỉ tập trung đo đạc thời gian thực thi của các lớp tích chập (Convolutional Layers), vốn là thành phần chiếm tỷ trọng tính toán lớn nhất trong mạng CNN. Chiến lược xử lý được lựa chọn là Batch Size = 1 nhằm tối ưu hóa độ trễ cho tác vụ xử lý từng ảnh đơn lẻ. Về cấu hình bộ nhớ, đồ án giả lập kiến trúc bộ nhớ tách biệt (Separate Off-chip Memory), trong đó Trọng số (Weights) và Dữ liệu (Activations) được truy xuất trên các kênh độc lập để tối ưu băng thông.

\section{Đánh giá khả năng xử lý trên AlexNet}
\label{sec:alexnet_eval}

AlexNet là một mạng nơ-ron tích chập điển hình, được đặc trưng bởi việc sử dụng các bộ lọc kích thước lớn ở các lớp đầu tiên ($11\times11$, $5\times5$). Để đánh giá hiệu năng, đồ án thực hiện chạy quá trình sinh mã (codegen) nhằm phân tích mối tương quan giữa số lượng phần tử xử lý (PE) và thời gian hoàn thành mô hình. Kết quả phân tích được thể hiện qua biểu đồ dưới đây.

\begin{figure}[H]
    \centering
    % 
    % Thay thế 'alexnet_pe_chart.png' bằng tên file ảnh thực tế của bạn
    \includegraphics[width=0.8\textwidth]{image/6/alexnet_pe_chart.png}
    \caption{Biểu đồ tương quan giữa số lượng PE và độ trễ xử lý trên AlexNet}
    \label{fig:alexnet_chart}
\end{figure}

Quan sát biểu đồ tại Hình \ref{fig:alexnet_chart}, có thể thấy điểm tối ưu nhất đạt được tại cấu hình $PE = 396$ với độ trễ (latency) là $47.04$ ms, tương đương tốc độ khung hình $21.26$ fps. Nguyên nhân là khi tăng số lượng PE, số lượng các kênh bản đồ đặc trưng đầu ra (ofmap) được tính toán song song sẽ tăng lên, đồng nghĩa với việc số lần phải tải lại toàn bộ bản đồ đặc trưng đầu vào (ifmap) giảm xuống. Với các giá trị $T_m$ tăng dần, thời gian xử lý giảm xuống rất nhanh. Tuy nhiên, khi chênh lệch giữa thời gian tải ifmap và thời gian tải ofmap không còn đáng kể, tốc độ giảm của thời gian xử lý sẽ bắt đầu bão hòa và chậm dần. Kết quả mô phỏng chi tiết với giới hạn tài nguyên 572 PEs được trình bày tại Bảng \ref{tab:alexnet_breakdown}.

\begin{table}[H]
\centering
\caption{Chi tiết hiệu năng từng lớp của AlexNet (Cập nhật)}
\label{tab:alexnet_breakdown}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
\multirow{2}{*}{\textbf{Layer}} & \multirow{2}{*}{\textbf{Filter / Channels}} & \multirow{2}{*}{\textbf{Map Size}} & \multirow{2}{*}{\textbf{PE Used}} & \multicolumn{3}{c}{\textbf{Optimized Config}} & \multirow{2}{*}{\textbf{Latency (ms)}} & \multirow{2}{*}{\textbf{Bottleneck}} \\ \cmidrule(lr){5-7}
 &  &  &  & $\mathbf{T_k}$ & $\mathbf{T_m}$ & $\mathbf{T_h}$ &  &  \\ \midrule
Conv1 & $11\times11 / 96$ & $224 \times 224$ & 396 & 3 & 12 & 1 & 8.12 & Mixed \\
Conv2 & $5\times5 / 256$ & $27 \times 27$ & 180 & 3 & 12 & 1 & 13.60 & Mixed \\
Conv3 & $3\times3 / 384$ & $13 \times 13$ & 108 & 3 & 12 & 1 & 7.25 & Memory \\
Conv4 & $3\times3 / 384$ & $13 \times 13$ & 108 & 3 & 12 & 1 & 10.71 & Memory \\
Conv5 & $3\times3 / 256$ & $13 \times 13$ & 108 & 3 & 12 & 1 & 7.36 & Memory \\ \midrule
\textbf{Total} & \textbf{--} & \textbf{--} & \textbf{Max 396} & \textbf{--} & \textbf{--} & \textbf{--} & \textbf{47.04} & \textbf{Memory} \\ \bottomrule
\end{tabular}%
}
\end{table}

Dựa trên kết quả thực nghiệm tại Bảng \ref{tab:alexnet_breakdown}, mô hình AlexNet đạt tổng thời gian thực thi là $47,04$ ms. Tại hai lớp đầu tiên (\textit{Conv1} và \textit{Conv2}), hệ thống ghi nhận trạng thái \textit{Mixed Bound}, cho thấy hiệu năng đang bị kìm hãm đồng thời bởi năng lực tính toán của mảng PE và tốc độ đáp ứng của băng thông bộ nhớ. Trong đó, \textit{Conv2} có độ trễ cao nhất ($13,60$ ms) do phải xử lý khối lượng tính toán lớn cùng áp lực truyền tải dữ liệu cao. 

Từ lớp \textit{Conv3} đến \textit{Conv5}, nút thắt cổ chai chuyển dịch hoàn toàn sang \textit{Memory Bound}. Mặc dù số lượng PE huy động thực tế giảm xuống, tốc độ truy xuất từ bộ nhớ ngoài vẫn không kịp cung cấp dữ liệu cho các đơn vị tính toán, dẫn đến việc lãng phí tài nguyên phần cứng. Tổng kết lại, thực nghiệm cho thấy hệ thống đang gặp thách thức về băng thông (\textit{Memory Wall}), do đó các giải pháp tối ưu trong tương lai cần tập trung vào việc tăng cường khả năng tái sử dụng dữ liệu (\textit{data reuse}) thay vì mở rộng quy mô mảng PE.
\section{Đánh giá khả năng xử lý trên VGG-16}
\label{sec:vgg_eval}    

Để kiểm chứng khả năng chịu tải của hệ thống đối với các mạng nơ-ron tích chập có độ sâu lớn, đồ án thực hiện mô phỏng trên mô hình VGG-16. Quá trình sinh mã và phân tích sự tương quan giữa số lượng PE và thời gian hoàn thành mô hình cho kết quả như biểu đồ sau.

\begin{figure}[H]
    \centering
    % 
    % Thay thế 'vgg16_pe_chart.png' bằng tên file ảnh thực tế của bạn
    \includegraphics[width=0.8\textwidth]{image/6/vgg16_pe_chart.png}
    \caption{Biểu đồ tương quan giữa số lượng PE và độ trễ xử lý trên VGG-16}
    \label{fig:vgg16_chart}
\end{figure}

Dựa vào biểu đồ Hình \ref{fig:vgg16_chart}, điểm tối ưu nhất được xác định tại $PE = 384$ với độ trễ đạt $266.67$ ms, tương đương $3.75$ fps. Tương tự như AlexNet, việc tăng số lượng PE giúp tăng số kênh ofmap được tính toán song song và giảm số lần tải lại ifmap. Tuy nhiên, khi độ trễ giữa các lần truy cập bộ nhớ giảm xuống đến mức bão hòa, đường cong hiệu năng cũng dần đi ngang. Kết quả mô phỏng chi tiết trên tập cấu hình phần cứng tối ưu với giới hạn 390 PEs được trình bày tại Bảng \ref{tab:vgg16_breakdown}.

\begin{table}[H]
\centering
\caption{Chi tiết hiệu năng từng lớp của VGG-16}
\label{tab:vgg16_breakdown}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
\multirow{2}{*}{\textbf{Layer}} & \multirow{2}{*}{\textbf{Filter / Channels}} & \multirow{2}{*}{\textbf{Map Size}} & \multirow{2}{*}{\textbf{PE Used}} & \multicolumn{3}{c}{\textbf{Optimized Config}} & \multirow{2}{*}{\textbf{Latency (ms)}} & \multirow{2}{*}{\textbf{Bottleneck}} \\ \cmidrule(lr){5-7}
 &  &  &  & $\mathbf{T_k}$ & $\mathbf{T_m}$ & $\mathbf{T_h}$ &  &  \\ \midrule
Conv1\_1 & $3\times3 / 64$ & $224 \times 224$ & 384 & 2 & 64 & 1 & 17.07 & Mixed \\
Conv1\_2 & $3\times3 / 64$ & $224 \times 224$ & 384 & 2 & 64 & 1 & 39.90 & Mixed \\ \midrule
Conv2\_1 & $3\times3 / 128$ & $112 \times 112$ & 384 & 2 & 64 & 1 & 19.95 & Mixed \\
Conv2\_2 & $3\times3 / 128$ & $112 \times 112$ & 384 & 2 & 64 & 1 & 31.99 & Mixed \\ \midrule
Conv3\_1 & $3\times3 / 256$ & $56 \times 56$ & 384 & 2 & 64 & 1 & 16.00 & Mixed \\
Conv3\_2 & $3\times3 / 256$ & $56 \times 56$ & 384 & 2 & 64 & 1 & 28.04 & Mixed \\
Conv3\_3 & $3\times3 / 256$ & $56 \times 56$ & 384 & 2 & 64 & 1 & 28.04 & Mixed \\ \midrule
Conv4\_1 & $3\times3 / 512$ & $28 \times 28$ & 384 & 2 & 64 & 1 & 14.02 & Mixed \\
Conv4\_2 & $3\times3 / 512$ & $28 \times 28$ & 384 & 2 & 64 & 1 & 26.06 & Mixed \\
Conv4\_3 & $3\times3 / 512$ & $28 \times 28$ & 384 & 2 & 64 & 1 & 26.06 & Mixed \\ \midrule
Conv5\_1 & $3\times3 / 512$ & $14 \times 14$ & 384 & 2 & 64 & 1 & 6.52 & Mixed \\
Conv5\_2 & $3\times3 / 512$ & $14 \times 14$ & 384 & 2 & 64 & 1 & 6.52 & Mixed \\
Conv5\_3 & $3\times3 / 512$ & $14 \times 14$ & 384 & 2 & 64 & 1 & 6.52 & Mixed \\ \midrule
\textbf{Total} & \textbf{--} & \textbf{--} & \textbf{Max 384} & \textbf{--} & \textbf{--} & \textbf{--} & \textbf{266.66} & \textbf{Mixed} \\ \bottomrule
\end{tabular}%
}
\end{table}

Kết quả thực nghiệm tại Bảng \ref{tab:vgg16_breakdown} cho thấy mô hình VGG-16 đạt tổng thời gian thực thi là $266,66$ ms với cấu hình phần cứng huy động ổn định $384$ PE. Điểm đặc biệt toàn bộ các lớp từ \textit{Conv1\_1} đến \textit{Conv5\_3} đều duy trì trạng thái \textit{Mixed Bound}. Điều này chứng tỏ cấu hình tối ưu hóa $T_m = 64$ đã tạo ra sự cân bằng nhất định giữa năng lực tính toán và lưu lượng dữ liệu, khiến hệ thống bị giới hạn đồng thời bởi cả băng thông bộ nhớ và tốc độ xử lý của mảng PE trên mọi tầng kiến trúc.

Độ trễ có xu hướng giảm dần tại các tầng sâu hơn (từ $39,90$ ms ở \textit{Conv1\_2} xuống còn $6,52$ ms ở các lớp \textit{Conv5}), hệ quả trực tiếp của việc thu nhỏ kích thước bản đồ đặc trưng (\textit{Map Size}) dù số lượng kênh tăng mạnh. Việc duy trì số lượng PE hoạt động tối đa xuyên suốt các lớp cho thấy hiệu suất khai thác phần cứng của thiết kế đối với VGG-16 là rất cao. Tuy nhiên, để tối ưu hóa thêm tổng thời gian thực thi, cần có những điều chỉnh linh hoạt hơn về tham số $T_k$ và $T_m$ nhằm thoát khỏi trạng thái nghẽn hỗn hợp tại các lớp có khối lượng tính toán lớn ở giai đoạn đầu.

\section{Đánh giá khả năng xử lý trên MobileNet v1}
\label{sec:mobilenet_eval}

Khác với VGG-16, MobileNet v1 sử dụng kiến trúc tích chập tách biệt theo chiều sâu (Depthwise Separable Convolution) nhằm giảm khối lượng tính toán. Đồ án tiến hành chạy codegen để phân tích sự tương quan giữa số lượng PE và thời gian hoàn thành mô hình, kết quả được thể hiện trong biểu đồ sau.

\begin{figure}[H]
    \centering
    % 
    % Thay thế 'mobilenet_pe_chart.png' bằng tên file ảnh thực tế của bạn
    \includegraphics[width=0.8\textwidth]{image/6/mobilenet_pe_chart.png}
    \caption{Biểu đồ tương quan giữa số lượng PE và độ trễ xử lý trên MobileNet v1}
    \label{fig:mobilenet_chart}
\end{figure}

Dựa trên biểu đồ Hình \ref{fig:mobilenet_chart}, điểm tối ưu nhất đạt được tại $PE = 384$ với độ trễ $65.75$ ms, tương đương $15.2$ fps. Tốc độ giảm của thời gian hoàn thành khi tăng số PE chậm hơn rất nhiều so với biểu đồ của AlexNet. Lý do chính là hệ thống không vận dụng được cơ chế tích luỹ theo chiều sâu, vốn là điểm mạnh của mô hình tại các lớp Depthwise Convolution. Điều này dẫn tới thời gian xử lý không giảm đáng kể ở các lớp này, mà chủ yếu chỉ được cải thiện ở các lớp Pointwise Convolution và Standard Convolution. Kết quả mô phỏng trên tập cấu hình phần cứng tối ưu với giới hạn 385 PEs được trình bày tại Bảng \ref{tab:mobilenet_breakdown}.
\begin{table}[H]
\centering
\caption{Chi tiết hiệu năng từng lớp của MobileNet v1}
\label{tab:mobilenet_breakdown}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
\multirow{2}{*}{\textbf{Layer}} & \multirow{2}{*}{\textbf{Filter / Channels}} & \multirow{2}{*}{\textbf{Map Size}} & \multirow{2}{*}{\textbf{PE Used}} & \multicolumn{3}{c}{\textbf{Optimized Config}} & \multirow{2}{*}{\textbf{Latency (ms)}} & \multirow{2}{*}{\textbf{Bottleneck}} \\ \cmidrule(lr){5-7}
 &  &  &  & $\mathbf{T_k}$ & $\mathbf{T_m}$ & $\mathbf{T_h}$ &  &  \\ \midrule
Standard Conv (L0) & $3\times3 / 32$ & $224 \times 224$ & 96 & 1 & 32 & 1 & 3.39 & Mixed \\ \midrule
Depthwise (L1) & $3\times3 / 32$ & $112 \times 112$ & 3 & 1 & 1 & 1 & 4.02 & Mixed \\
Pointwise (L2) & $1\times1 / 64$ & $112 \times 112$ & 64 & 1 & 64 & 1 & 6.02 & Memory \\ \midrule
Depthwise (L3) & $3\times3 / 64$ & $56 \times 56$ & 3 & 1 & 1 & 23 & 6.70 & Mixed \\
Pointwise (L4) & $1\times1 / 128$ & $56 \times 56$ & 128 & 1 & 128 & 1 & 3.01 & Memory \\ \midrule
Depthwise (L5) & $3\times3 / 128$ & $56 \times 56$ & 3 & 1 & 1 & 1 & 4.02 & Mixed \\
Pointwise (L6) & $1\times1 / 128$ & $56 \times 56$ & 128 & 1 & 128 & 1 & 4.01 & Memory \\ \midrule
Depthwise (L7) & $3\times3 / 128$ & $28 \times 28$ & 3 & 1 & 1 & 56 & 2.57 & Mixed \\
Pointwise (L8) & $1\times1 / 256$ & $28 \times 28$ & 128 & 1 & 128 & 1 & 2.01 & Memory \\ \midrule
Depthwise (L9) & $3\times3 / 256$ & $28 \times 28$ & 3 & 1 & 1 & 1 & 2.01 & Mixed \\
Pointwise (L10) & $1\times1 / 256$ & $28 \times 28$ & 128 & 1 & 128 & 1 & 3.01 & Memory \\ \midrule
Depthwise (L11) & $3\times3 / 256$ & $14 \times 14$ & 3 & 1 & 1 & 28 & 1.27 & Mixed \\
Pointwise (L12) & $1\times1 / 512$ & $14 \times 14$ & 128 & 1 & 128 & 1 & 1.51 & Memory \\ \midrule
Avg. DW (L13-25 odd) & $3\times3 / 512$ & $14 \times 14$ & 3 & 1 & 1 & $1^*$ & 0.86$^\dagger$ & Mixed \\
Avg. PW (L14-26 even) & $1\times1 / 512$ & $14 \times 14$ & 128 & 1 & 128 & 1 & 2.30$^\dagger$ & Memory \\ \midrule
\textbf{Total} & \textbf{--} & \textbf{--} & \textbf{Max 128} & \textbf{--} & \textbf{--} & \textbf{--} & \textbf{65.75} & \textbf{Mixed} \\ \bottomrule
\multicolumn{9}{l}{\small $^*$ Giá trị $T_h$ thay đổi tùy lớp. $^\dagger$ Giá trị trung bình dựa trên tổng chu kỳ thực tế của các lớp lặp lại (L13-L26).}
\end{tabular}%
}
\end{table}
Dựa trên kết quả thực nghiệm tại Bảng \ref{tab:mobilenet_breakdown}, mô hình MobileNet v1 đạt tổng thời gian thực thi là $65,75$ ms với mảng PE huy động tối đa $128$ đơn vị. Hệ thống ghi nhận sự phân hóa rõ rệt về nút thắt cổ chai giữa hai loại hình tích chập đặc trưng: các lớp \textit{Pointwise} luôn ở trạng thái \textit{Memory Bound}, trong khi các lớp \textit{Depthwise} và \textit{Standard Conv} duy trì trạng thái \textit{Mixed Bound}. 

Tại các lớp \textit{Pointwise}, dù đã tận dụng tối đa cấu hình song song $T_m = 128$, hiệu năng vẫn bị giới hạn bởi tốc độ truy xuất dữ liệu từ bộ nhớ ngoài do khối lượng tham số và đặc trưng lớn. Ngược lại, các lớp \textit{Depthwise} bộc lộ sự hạn chế trong việc khai thác tài nguyên khi chỉ huy động được $3$ PE ($T_m = 1$) do đặc thù tính toán đơn kênh, dẫn đến việc năng lực tính toán và băng thông rơi vào trạng thái nghẽn hỗn hợp với hiệu suất sử dụng phần cứng thấp. Tổng kết lại, kết quả thực nghiệm chỉ ra rằng hiệu năng của MobileNet v1 trên kiến trúc hiện tại bị kìm hãm đồng thời bởi giới hạn băng thông bộ nhớ tại các lớp tích chập điểm và sự thiếu tương thích về cấu trúc song song tại các lớp tích chập sâu.
\section{So sánh với các Nghiên cứu liên quan}
\label{sec:comparison}

Để đánh giá khách quan hiệu quả của kiến trúc đề xuất, chúng tôi thực hiện so sánh đối chứng với kết quả đo đạc thực tế trên silicon của chip gia tốc Eyeriss [Chen et al., ISSCC 2016]. Các thông số tham chiếu của Eyeriss được lấy từ cấu hình tối ưu với Batch Size $N=4$ cho AlexNet và $N=3$ cho VGG16.Nhằm đảm bảo tính tương đồng trong điều kiện thử nghiệm, kiến trúc đề xuất được cấu hình với 165 PE (xấp xỉ số lượng PE của Eyeriss), đồng thời sử dụng mô hình AlexNet với Grouped Convolution tại các lớp conv2, conv4 và conv5 đúng theo nguyên bản. Bên cạnh đó, các tham số hệ thống cũng được đồng bộ hóa với thiết kế Eyeriss: băng thông bộ nhớ ngoài (off-chip memory) giới hạn ở mức 480MB/s và độ chính xác tính toán là 16-bit fixed-point. Kết quả so sánh chi tiết được trình bày tại Bảng \ref{tab:comparison_eyeriss}.

\begin{table}[H]
\centering
\caption{So sánh hiệu năng xử lý Convolution trên AlexNet và VGG16}
\label{tab:comparison_eyeriss}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|c|c|}
\hline
\textbf{Thông số} & \textbf{Đề xuất (Ours)} & \textbf{Eyeriss [Chen et al.]} \\ \hline
Số lượng PE & 165 (AlexNet) - 162 (VGG16) & 168 \\ \hline
Kiến trúc bộ nhớ & Separate Off-chip Memory & Shared DRAM \\ \hline
Chiến lược xử lý & \textbf{Batch Size = 1} (Real-time) & \textbf{Batch Size = 3-4} (Throughput) \\ \hline
\textbf{AlexNet (Latency)} & 71.24 ms (14.03 fps) & \textbf{28.57 ms}* (35.0 fps) \\ \hline
\textbf{VGG16 (Latency)} & \textbf{555.8 ms} (1.80 fps) & 1428.57 ms** (0.7 fps) \\ \hline
\end{tabular}%
}
\vspace{0.2cm}
\footnotesize{
\textit{*AlexNet Eyeriss: Tính trung bình trên Batch=4 ($N=4$).} \\
\textit{**VGG16 Eyeriss: Tính trung bình trên Batch=3 ($N=3$).}
}
\end{table}


Dựa trên kết quả đối sánh chi tiết tại Bảng \ref{tab:comparison_eyeriss}, kiến trúc đề xuất thể hiện những ưu thế chiến lược về khả năng xử lý thời gian thực và hiệu quả quản lý băng thông so với kiến trúc Eyeriss. Sự khác biệt rõ rệt nhất được ghi nhận tại mô hình VGG16, nơi giải pháp của nhóm nghiên cứu đạt hiệu năng vượt trội với độ trễ thấp hơn khoảng \textbf{2,59 lần} (chỉ $555,8$ ms so với $1428,57$ ms của Eyeriss). Kết quả đột phá này đạt được nhờ việc áp dụng kiến trúc bộ nhớ tách biệt (\textit{Separate Off-chip Memory}), giúp mở rộng băng thông truy xuất dữ liệu độc lập cho trọng số và bản đồ đặc trưng. Cách tiếp cận này giúp giải tỏa triệt để hiện tượng nghẽn mạch bộ nhớ (\textit{Memory Bottleneck}) — một hạn chế cố hữu của các kiến trúc sử dụng bộ nhớ chia sẻ (\textit{Shared DRAM}) khi phải đối mặt với khối lượng dữ liệu khổng lồ của các mạng nơ-ron sâu như VGG16.

Đối với mô hình AlexNet, mặc dù Eyeriss đạt thông lượng cao hơn ($35,0$ fps) nhờ tận dụng cơ chế xử lý theo lô (\textit{Batch Size = 4}), kiến trúc đề xuất vẫn khẳng định được giá trị thực tiễn với độ trễ phản hồi đơn lẻ đạt $71,24$ ms tại $N=1$. Trong khi Eyeriss ưu tiên tối ưu hóa hiệu suất tổng thể (\textit{Throughput}) dựa trên việc tích lũy dữ liệu, giải pháp của nhóm hướng tới các ứng dụng thực tế yêu cầu phản hồi tức thời (\textit{Real-time}). Việc loại bỏ độ trễ tích lũy (\textit{Batching Latency}) giúp hệ thống đề xuất trở nên phù hợp hơn cho các bài toán biên (\textit{Edge computing}), nơi tính thời điểm của thông tin quan trọng hơn lưu lượng xử lý tổng thể. Tổng kết lại, sự kết hợp giữa mảng PE linh hoạt và kiến trúc bộ nhớ tối ưu đã giúp hệ thống đề xuất đạt được sự cân bằng hiệu quả giữa năng lực tính toán và tốc độ phản hồi trên các cấu trúc mạng có độ phức tạp khác nhau.