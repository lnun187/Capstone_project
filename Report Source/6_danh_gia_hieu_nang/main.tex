\chapter{Ước lượng hiệu năng}
\label{ch:evaluation}

Chương này trình bày các kết quả thực nghiệm thu được từ mô hình ước lượng hiệu năng của kiến trúc phần cứng được đề xuất trong đồ án. Nội dung đánh giá tập trung vào việc phân tích hiệu quả của thuật toán tối ưu tham số (Codegen) và khả năng xử lý của phần cứng đối với ba lớp mô hình đại diện gồm AlexNet, VGG-16 và MobileNetV1. Bên cạnh đó, nhóm thực hiện cũng tiến hành so sánh kết quả với kiến trúc Eyeriss để làm rõ các ưu điểm và hạn chế của giải pháp thiết kế.

\section{Môi trường và Phương pháp thực nghiệm}

Nhằm đánh giá để tiên liệu trước về hiệu năng của đồ án này, kiến trúc được đánh giá thông qua một mô hình ước lượng (Analytical Estimator) xây dựng bằng ngôn ngữ C++. Mô hình này hiện thực hóa các công thức toán học đã được thiết lập tại Chương 4 nhằm dự báo độ trễ và tài nguyên tiêu thụ.

Các tham số cấu hình cho quá trình mô phỏng được thiết lập dựa trên các ràng buộc phần cứng dự kiến. Cụ thể, hệ thống hoạt động ở tần số $200 \text{ MHz}$ với số lượng đơn vị xử lý (PEs) tiêu chuẩn là 385. Tốc độ của off-chip memory là 1 byte 1 cycle tương ứng tần số 200 MHz. Các giá trị đã được quantized ở dạng int8.Phạm vi đánh giá chỉ tập trung đo đạc thời gian thực thi của các lớp tích chập (Convolutional Layers), vốn là thành phần chiếm tỷ trọng tính toán lớn nhất trong mạng CNN. Chiến lược xử lý được lựa chọn là Batch Size = 1 nhằm tối ưu hóa độ trễ cho tác vụ xử lý từng ảnh đơn lẻ. Về cấu hình bộ nhớ, đồ án giả lập kiến trúc bộ nhớ tách biệt (Separate Off-chip Memory), trong đó Trọng số (Weights) và Dữ liệu (Activations) được truy xuất trên các kênh độc lập để tối ưu băng thông.

\section{Đánh giá khả năng xử lý trên AlexNet}
\label{sec:alexnet_eval}

AlexNet là một mạng nơ-ron tích chập điển hình, được đặc trưng bởi việc sử dụng các bộ lọc kích thước lớn ở các lớp đầu tiên ($11\times11$, $5\times5$). Để đánh giá hiệu năng, đồ án thực hiện chạy quá trình sinh mã (codegen) nhằm phân tích mối tương quan giữa số lượng phần tử xử lý (PE) và thời gian hoàn thành mô hình. Kết quả phân tích được thể hiện qua biểu đồ dưới đây.

\begin{figure}[H]
    \centering
    % 
    % Thay thế 'alexnet_pe_chart.png' bằng tên file ảnh thực tế của bạn
    \includegraphics[width=0.8\textwidth]{image/6/alexnet_pe_chart.png}
    \caption{Biểu đồ tương quan giữa số lượng PE và độ trễ xử lý trên AlexNet}
    \label{fig:alexnet_chart}
\end{figure}

Quan sát biểu đồ tại Hình \ref{fig:alexnet_chart}, có thể thấy điểm tối ưu nhất đạt được tại cấu hình $PE = 704$ với độ trễ (latency) là $14.1$ ms, tương đương tốc độ khung hình $70.92$ fps. Nguyên nhân là khi tăng số lượng PE, số lượng các kênh bản đồ đặc trưng đầu ra (ofmap) được tính toán song song sẽ tăng lên, đồng nghĩa với việc số lần phải tải lại toàn bộ bản đồ đặc trưng đầu vào (ifmap) giảm xuống. Với các giá trị $T_m$ tăng dần, thời gian xử lý giảm xuống rất nhanh. Tuy nhiên, khi chênh lệch giữa thời gian tải ifmap và thời gian tải ofmap không còn đáng kể, tốc độ giảm của thời gian xử lý sẽ bắt đầu bão hòa và chậm dần. Kết quả mô phỏng chi tiết với giới hạn tài nguyên 704 PEs được trình bày tại Bảng \ref{tab:alexnet_breakdown}.

\begin{table}[H]
\centering
\caption{Chi tiết hiệu năng từng lớp của AlexNet (Cập nhật theo Log - Total: 14.10 ms)}
\label{tab:alexnet_breakdown}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lccccccc}
\toprule
\multirow{2}{*}{\textbf{Layer}} & \multirow{2}{*}{\textbf{Filter Size}} & \multirow{2}{*}{\textbf{PE Used}} & \multicolumn{3}{c}{\textbf{Optimized Config}} & \multirow{2}{*}{\textbf{Latency (ms)}} & \multirow{2}{*}{\textbf{Bottleneck}} \\ \cmidrule(lr){4-6}
 &  &  & $\mathbf{T_k}$ & $\mathbf{T_m}$ & $\mathbf{T_h}$ &  &  \\ \midrule
Conv1 & $11\times11$ & 528 & 1 & 48 & 11 & 5.17 & Compute \\
Conv2 & $5\times5$   & 640 & 1 & 64 & 5  & 3.53 & Compute \\
Conv3 & $3\times3$   & 576 & 1 & 64 & 3  & 1.62 & Memory \\
Conv4 & $3\times3$   & 576 & 1 & 64 & 3  & 2.27 & Memory \\
Conv5 & $3\times3$   & 576 & 1 & 64 & 3  & 1.51 & Memory \\ \midrule
\textbf{Total} & \textbf{-} & \textbf{Max 640} & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{14.10} & \textbf{Mixed} \\ \bottomrule
\end{tabular}%
}
\end{table}

Dựa trên kết quả thực nghiệm được trình bày tại Bảng \ref{tab:alexnet_breakdown}, nhóm em có những phân tích cụ thể về hiệu năng của mô hình AlexNet với tổng thời gian thực thi là $14.10$ ms như sau:

Trước hết, về đặc thù tính toán, hệ thống cho thấy một sự phân hóa rõ rệt giữa các tầng dựa trên kích thước bộ lọc. Tại hai lớp đầu tiên là Conv1 và Conv2, do sử dụng các bộ lọc có kích thước lớn ($11 \times 11$ và $5 \times 5$), mật độ tính toán trên mỗi đơn vị dữ liệu là rất cao. Điều này cho phép hệ thống huy động tối đa tài nguyên với số lượng PE sử dụng lần lượt là $528$ và $640$. Trong giai đoạn này, hệ thống rơi vào trạng thái \textit{Compute Bound}, nghĩa là năng lực xử lý của mảng PE là yếu tố chính quyết định độ trễ. Việc tối ưu hóa các tham số cấu hình như $T_m$ và $T_h$ đã giúp tận dụng tốt sức mạnh phần cứng để xử lý khối lượng công việc khổng lồ, chiếm tỷ trọng lớn trong tổng thời gian thực thi.

Tuy nhiên, đối với các lớp từ Conv3 đến Conv5, mặc dù các tham số song song hóa vẫn được duy trì ở mức cao ($T_m = 64$ và sử dụng $576$ PEs), nhưng điểm nghẽn hệ thống đã chuyển dịch hoàn toàn sang trạng thái \textit{Memory Bound}. Do kích thước bộ lọc giảm xuống đáng kể ($3 \times 3$), khối lượng tính toán trên mỗi lần truy xuất dữ liệu không còn đủ lớn để che giấu độ trễ của bộ nhớ. Hệ quả là mảng PE thường xuyên phải chờ dữ liệu, khiến thời gian xử lý tại các lớp này phụ thuộc vào băng thông hơn là tốc độ tính toán thuần túy. Đặc biệt, lớp Conv4 ghi nhận mức độ trễ $2.27$ ms, cao hơn so với Conv3 và Conv5, cho thấy đây là điểm nhạy cảm về mặt lưu lượng dữ liệu.

Tổng kết lại, mô hình đang vận hành dưới một cơ chế điểm nghẽn hỗn hợp (\textit{Mixed Bottleneck}). Để cải thiện tổng độ trễ $14.10$ ms này, việc chỉ tăng thêm số lượng PE sẽ không mang lại hiệu quả tối ưu cho các lớp sau. Thay vào đó, cần có các giải pháp về cải thiện băng thông hoặc tối ưu hóa sơ đồ luồng dữ liệu (\textit{Dataflow}) để giải quyết tình trạng nghẽn bộ nhớ tại các tầng có bộ lọc kích thước nhỏ.

\section{Đánh giá khả năng xử lý trên VGG-16}
\label{sec:vgg_eval}

Để kiểm chứng khả năng chịu tải của hệ thống đối với các mạng nơ-ron tích chập có độ sâu lớn, đồ án thực hiện mô phỏng trên mô hình VGG-16. Quá trình sinh mã và phân tích sự tương quan giữa số lượng PE và thời gian hoàn thành mô hình cho kết quả như biểu đồ sau.

\begin{figure}[H]
    \centering
    % 
    % Thay thế 'vgg16_pe_chart.png' bằng tên file ảnh thực tế của bạn
    \includegraphics[width=0.8\textwidth]{image/6/vgg16_pe_chart.png}
    \caption{Biểu đồ tương quan giữa số lượng PE và độ trễ xử lý trên VGG-16}
    \label{fig:vgg16_chart}
\end{figure}

Dựa vào biểu đồ Hình \ref{fig:vgg16_chart}, điểm tối ưu nhất được xác định tại $PE = 390$ với độ trễ đạt $216.99$ ms, tương đương $4.61$ fps. Tương tự như AlexNet, việc tăng số lượng PE giúp tăng số kênh ofmap được tính toán song song và giảm số lần tải lại ifmap. Tuy nhiên, khi độ trễ giữa các lần truy cập bộ nhớ giảm xuống đến mức bão hòa, đường cong hiệu năng cũng dần đi ngang. Kết quả mô phỏng chi tiết trên tập cấu hình phần cứng tối ưu với giới hạn 390 PEs được trình bày tại Bảng \ref{tab:vgg16_breakdown}.

\begin{table}[H]
\centering
\caption{Chi tiết hiệu năng từng lớp của VGG-16 (Cập nhật theo Log - Total: 216.99 ms)}
\label{tab:vgg16_breakdown}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
\multirow{2}{*}{\textbf{Layer}} & \multirow{2}{*}{\textbf{Filter / Channels}} & \multirow{2}{*}{\textbf{Map Size}} & \multirow{2}{*}{\textbf{PE Used}} & \multicolumn{3}{c}{\textbf{Optimized Config}} & \multirow{2}{*}{\textbf{Latency (ms)}} & \multirow{2}{*}{\textbf{Bottleneck}} \\ \cmidrule(lr){5-7}
 & & & & $\mathbf{T_k}$ & $\mathbf{T_m}$ & $\mathbf{T_h}$ & & \\ \midrule
Conv1\_1 & $3\times3 / 64$ & $224 \times 224$ & 198 & 1 & 33 & 224 & 10.13 & Memory \\
Conv1\_2 & $3\times3 / 64$ & $224 \times 224$ & 384 & 1 & 64 & 3 & 32.12 & Memory \\
Conv2\_1 & $3\times3 / 128$ & $112 \times 112$ & 390 & 1 & 65 & 112 & 12.16 & Memory \\
Conv2\_2 & $3\times3 / 128$ & $112 \times 112$ & 384 & 1 & 64 & 3 & 24.09 & Memory \\
Conv3\_1 & $3\times3 / 256$ & $56 \times 56$ & 384 & 1 & 64 & 3 & 12.04 & Memory \\
Conv3\_2 & $3\times3 / 256$ & $56 \times 56$ & 384 & 1 & 64 & 3 & 24.09 & Compute \\
Conv3\_3 & $3\times3 / 256$ & $56 \times 56$ & 384 & 1 & 64 & 3 & 24.09 & Compute \\
Conv4\_1 & $3\times3 / 512$ & $28 \times 28$ & 384 & 1 & 64 & 3 & 12.04 & Compute \\
Conv4\_2 & $3\times3 / 512$ & $28 \times 28$ & 384 & 1 & 64 & 3 & 24.09 & Compute \\
Conv4\_3 & $3\times3 / 512$ & $28 \times 28$ & 384 & 1 & 64 & 3 & 24.09 & Compute \\
Conv5\_1 & $3\times3 / 512$ & $14 \times 14$ & 384 & 1 & 64 & 3 & 6.02 & Compute \\
Conv5\_2 & $3\times3 / 512$ & $14 \times 14$ & 384 & 1 & 64 & 3 & 6.02 & Compute \\
Conv5\_3 & $3\times3 / 512$ & $14 \times 14$ & 384 & 1 & 64 & 3 & 6.02 & Compute \\ \midrule
\textbf{Total} & \textbf{--} & \textbf{--} & \textbf{Max 390} & \textbf{--} & \textbf{--} & \textbf{--} & \textbf{216.99} & \textbf{Mixed} \\ \bottomrule
\end{tabular}%
}
\end{table}

Kết quả mô phỏng thực tế xác nhận tính hiệu quả cao trong chiến lược phân bổ tài nguyên phần cứng cho mô hình VGG-16 với tổng thời gian thực thi đạt 216.99 ms. Việc thiết lập giới hạn phần cứng tại mức MAX\_M = 65 và PE Limit = 390 cho thấy sự tương thích đặc biệt với kiến trúc của VGG-16, nơi các tham số về kênh (channels) thường là bội số của 64 hoặc 32. Hệ thống duy trì mức sử dụng tài nguyên rất cao, đạt tối đa 390 PEs tại lớp Conv2\_1 và ổn định ở mức 384 PEs cho hầu hết các lớp còn lại, minh chứng cho khả năng song song hóa tối ưu trên chiều kênh đầu ra ($T_m$) và chiều cao khối dữ liệu ($T_h$).

Sự phân hóa về điểm nghẽn hệ thống (Bottleneck) trong bảng dữ liệu phản ánh rõ rệt tác động của việc tăng cường năng lực tính toán. Tại các tầng đầu tiên của mạng (từ Conv1\_1 đến Conv3\_1), hệ thống hoàn toàn bị giới hạn bởi băng thông bộ nhớ (Memory Bound). Điều này xảy ra do kích thước bản đồ đặc trưng (Map Size) còn quá lớn ($224 \times 224$ và $112 \times 112$), khiến khối lượng dữ liệu cần nạp vào và xuất ra vượt quá tốc độ xử lý của các đơn vị PE, dù số lượng PE sử dụng đã đạt ngưỡng tối đa. Trong giai đoạn này, sự chênh lệch chu kỳ (Difference cycle) giữa bộ nhớ và tính toán là số dương rất lớn, khẳng định rằng các PE phải chờ đợi dữ liệu từ bộ nhớ đệm.

Ngược lại, bắt đầu từ lớp Conv3\_2 trở đi, khi kích thước bản đồ đặc trưng giảm xuống mức $56 \times 56$ và nhỏ hơn, hệ thống chuyển sang trạng thái giới hạn tính toán (Compute Bound). Lúc này, độ sâu của các bộ lọc tăng lên khiến khối lượng phép tính nhân tích lũy (MAC) trở nên đồ sộ, đủ để che lấp độ trễ truy xuất bộ nhớ. Với tổng thời gian xử lý rút ngắn xuống còn 216.99 ms so với các cấu hình thấp hơn, hệ thống đã đạt đến điểm tối ưu về hiệu suất, cho phép đáp ứng tốt các ứng dụng nhận diện hình ảnh thời gian thực, đồng thời chỉ ra rằng các nỗ lực tối ưu hóa tiếp theo nên tập trung vào việc cải thiện băng thông bộ nhớ cho các lớp tích chập ban đầu.

\section{Đánh giá khả năng xử lý trên MobileNet v1}
\label{sec:mobilenet_eval}

Khác với VGG-16, MobileNet v1 sử dụng kiến trúc tích chập tách biệt theo chiều sâu (Depthwise Separable Convolution) nhằm giảm khối lượng tính toán. Đồ án tiến hành chạy codegen để phân tích sự tương quan giữa số lượng PE và thời gian hoàn thành mô hình, kết quả được thể hiện trong biểu đồ sau.

\begin{figure}[H]
    \centering
    % 
    % Thay thế 'mobilenet_pe_chart.png' bằng tên file ảnh thực tế của bạn
    \includegraphics[width=0.8\textwidth]{image/6/mobilenet_pe_chart.png}
    \caption{Biểu đồ tương quan giữa số lượng PE và độ trễ xử lý trên MobileNet v1}
    \label{fig:mobilenet_chart}
\end{figure}

Dựa trên biểu đồ Hình \ref{fig:mobilenet_chart}, điểm tối ưu nhất đạt được tại $PE = 384$ với độ trễ $76.64$ ms, tương đương $13$ fps. Tốc độ giảm của thời gian hoàn thành khi tăng số PE chậm hơn rất nhiều so với biểu đồ của AlexNet. Lý do chính là hệ thống không vận dụng được cơ chế tích luỹ theo chiều sâu, vốn là điểm mạnh của mô hình tại các lớp Depthwise Convolution. Điều này dẫn tới thời gian xử lý không giảm đáng kể ở các lớp này, mà chủ yếu chỉ được cải thiện ở các lớp Pointwise Convolution và Standard Convolution. Kết quả mô phỏng trên tập cấu hình phần cứng tối ưu với giới hạn 385 PEs được trình bày tại Bảng \ref{tab:mobilenet_breakdown}.

\begin{table}[H]
\centering
\caption{Hiệu năng chi tiết từng lớp của MobileNet v1 (Total Latency: 76.64 ms)}
\label{tab:mobilenet_breakdown}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lccccccc}
\toprule
\multirow{2}{*}{\textbf{Layer Type}} & \multirow{2}{*}{\textbf{Layer Idx}} & \multirow{2}{*}{\textbf{PE Used}} & \multicolumn{3}{c}{\textbf{Optimized Config}} & \multirow{2}{*}{\textbf{Latency (ms)}} & \multirow{2}{*}{\textbf{Bottleneck}} \\ \cmidrule(lr){4-6}
 &  &  & $\mathbf{T_k}$ & $\mathbf{T_m}$ & $\mathbf{T_h}$ &  &  \\ \midrule
Standard Conv & 0 & 96 & 1 & 32 & 3 & 2.77 & Memory \\ \midrule
Depthwise & 1 & 3 & 1 & 1 & 3 & 6.02 & Compute \\
Pointwise & 2 & 192 & 1 & 64 & 1 & 6.02 & Memory \\ \midrule
Depthwise & 3 & 3 & 1 & 1 & 3 & 7.99 & Compute \\
Pointwise & 4 & 384 & 1 & 128 & 1 & 3.01 & Memory \\ \midrule
Depthwise & 5 & 3 & 1 & 1 & 3 & 6.02 & Compute \\
Pointwise & 6 & 384 & 1 & 128 & 1 & 4.01 & Memory \\ \midrule
Depthwise & 7 & 3 & 1 & 1 & 3 & 3.98 & Compute \\
Pointwise & 8 & 384 & 1 & 128 & 1 & 2.01 & Memory \\ \midrule
Depthwise & 9 & 3 & 1 & 1 & 3 & 3.01 & Compute \\
Pointwise & 10 & 384 & 1 & 128 & 1 & 3.01 & Memory \\ \midrule
Depthwise & 11 & 3 & 1 & 1 & 3 & 1.97 & Compute \\
Pointwise & 12 & 384 & 1 & 128 & 1 & 1.51 & Memory \\ \midrule
Depthwise & 13 & 3 & 1 & 1 & 3 & 1.51 & Compute \\
Pointwise & 14, 16, 18, 20, 22 & 384 & 1 & 128 & 1 & 2.51 (avg) & Memory \\
Depthwise & 15, 17, 19, 21 & 3 & 1 & 1 & 3 & 1.51 (avg) & Compute \\ \midrule
Depthwise & 23 & 3 & 1 & 1 & 3 & 0.97 & Compute \\
Pointwise & 24 & 384 & 1 & 128 & 1 & 1.25 & Memory \\ \midrule
Depthwise & 25 & 3 & 1 & 1 & 3 & 0.75 & Compute \\
Pointwise & 26 & 384 & 1 & 128 & 1 & 2.26 & Memory \\ \midrule
\textbf{Total} & \textbf{All Layers} & \textbf{Max 384} & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{76.64} & \textbf{Mixed} \\ \bottomrule
\end{tabular}%
}
\vspace{0.2cm}

\footnotesize{\textit{*Ghi chú: Dựa trên log thực nghiệm, các lớp Depthwise bị giới hạn bởi tính toán (Compute Bound) do cấu hình $T_m=1$ dẫn đến số PE sử dụng rất thấp (3 PE), trong khi các lớp Pointwise bị giới hạn bởi băng thông bộ nhớ (Memory Bound) khi sử dụng tối đa 384 PE.}}
\end{table}

Dựa trên bảng số liệu thực nghiệm, kết quả cho thấy hệ thống có sự chuyển đổi trạng thái liên tục giữa \textit{Compute Bound} và \textit{Memory Bound} (hiện tượng Toggle Bottleneck), phản ánh chính xác đặc thù kiến trúc phân mảnh của mô hình MobileNet v1. Trong cơ chế này, các lớp Pointwise ($1\times1$ Conv) hầu như luôn rơi vào trạng thái nghẽn bộ nhớ (\textit{Memory Bound}). Do đặc tính tái sử dụng dữ liệu thấp nhưng khả năng song song hóa cực cao, hệ thống đã tận dụng triệt để 384 PEs với cấu hình tối ưu $T_m=128$ nhằm tiêu thụ dữ liệu nhanh hơn tốc độ cung cấp của băng thông, khiến hiệu năng bị giới hạn bởi tốc độ truy xuất từ bộ nhớ ngoài.

Ngược lại, các lớp Depthwise ($3\times3$ DW) tuy được log hệ thống đánh dấu là nghẽn tính toán (\textit{Compute Bound}), nhưng thực chất đây là hệ quả của hiện tượng giới hạn do kém hiệu quả trong việc sử dụng tài nguyên (\textit{under-utilization}). Cấu trúc đặc thù của phép toán Depthwise không có sự cộng gộp giữa các kênh ($C_{in} = C_{out}$), khiến cấu hình phần cứng hiện tại buộc phải giảm tham số tối ưu xuống mức thấp nhất là $T_m=1$. Hệ quả là trong tổng số 384 PEs sẵn có, chỉ có vỏn vẹn 3 PEs được kích hoạt để xử lý, trong khi 381 PEs còn lại rơi vào trạng thái nhàn rỗi, trực tiếp kéo dài thời gian tính toán của các lớp này một cách không cần thiết.

Đáng chú ý, mặc dù khối lượng tính toán lý thuyết của các lớp Depthwise là rất nhỏ so với Pointwise, chúng lại chiếm tới hơn $50\%$ tổng thời gian thực thi của toàn bộ mô hình (khoảng 38.2 ms trên tổng số 76.64 ms). Sự mất cân đối này chỉ ra một điểm yếu trong thiết kế phần cứng hiện tại khi chưa tối ưu cho các kiến trúc mạng nơ-ron hiện đại. Để đạt được độ trễ thấp hơn và tối ưu hóa hiệu suất trên mỗi đơn vị tài nguyên, kiến trúc phần cứng cần được cải tiến để hỗ trợ cơ chế song song hóa kênh (Channel Parallelism) đặc thù cho các lớp Depthwise, thay vì chỉ dựa trên các khối nhân ma trận truyền thống.
\section{So sánh với các Nghiên cứu liên quan}
\label{sec:comparison}

Để đánh giá khách quan hiệu quả của kiến trúc đề xuất, chúng tôi thực hiện so sánh đối chứng với kết quả đo đạc thực tế trên silicon của chip gia tốc Eyeriss [Chen et al., ISSCC 2016]. Các thông số tham chiếu của Eyeriss được lấy từ cấu hình tối ưu với Batch Size $N=4$ cho AlexNet và $N=3$ cho VGG16.Nhằm đảm bảo tính tương đồng trong điều kiện thử nghiệm, kiến trúc đề xuất được cấu hình với 165 PE (xấp xỉ số lượng PE của Eyeriss), đồng thời sử dụng mô hình AlexNet với Grouped Convolution tại các lớp conv2, conv4 và conv5 đúng theo nguyên bản. Bên cạnh đó, các tham số hệ thống cũng được đồng bộ hóa với thiết kế Eyeriss: băng thông bộ nhớ ngoài (off-chip memory) giới hạn ở mức 480MB/s và độ chính xác tính toán là 16-bit fixed-point. Kết quả so sánh chi tiết được trình bày tại Bảng \ref{tab:comparison_eyeriss}.

\begin{table}[H]
\centering
\caption{So sánh hiệu năng xử lý Convolution trên AlexNet và VGG16}
\label{tab:comparison_eyeriss}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|c|c|}
\hline
\textbf{Thông số} & \textbf{Đề xuất (Ours)} & \textbf{Eyeriss [Chen et al.]} \\ \hline
Số lượng PE & 165 & 168 \\ \hline
Kiến trúc bộ nhớ & Separate Off-chip Memory & Shared DRAM \\ \hline
Chiến lược xử lý & \textbf{Batch Size = 1} (Real-time) & \textbf{Batch Size = 3-4} (Throughput) \\ \hline
\textbf{AlexNet (Latency)} & 45.87 ms (21.8 fps) & \textbf{28.57 ms}* (35.0 fps) \\ \hline
\textbf{VGG16 (Latency)} & \textbf{510.48 ms} (1.96 fps) & 1428.57 ms** (0.7 fps) \\ \hline
\end{tabular}%
}
\vspace{0.2cm}
\footnotesize{
\textit{*AlexNet Eyeriss: Tính trung bình trên Batch=4 ($N=4$).} \\
\textit{**VGG16 Eyeriss: Tính trung bình trên Batch=3 ($N=3$).}
}
\end{table}

Kết quả so sánh cho thấy hai xu hướng đối lập tương ứng với độ phức tạp của mạng nơ-ron:

\begin{itemize}
    \item \textbf{Đối với VGG16 (Mạng sâu và nặng):} Kiến trúc đề xuất đạt hiệu năng vượt trội với độ trễ thấp hơn khoảng \textbf{2.78 lần} so với Eyeriss (514.31 ms so với 1428.57 ms). Kết quả này đạt được nhờ cấu hình phần cứng tối ưu ($T_m=28$) giúp tận dụng tối đa 100\% tài nguyên PE ở hầu hết các lớp. Đồng thời, trạng thái \textit{Compute Bound} ổn định chứng tỏ hệ thống bộ nhớ tách biệt đã loại bỏ được nút thắt cổ chai về dữ liệu mà các kiến trúc dùng chung bộ nhớ (Shared DRAM) thường gặp phải.
    
    \item \textbf{Đối với AlexNet (Mạng nông, có Grouped Convolution):} Eyeriss giữ lợi thế về thông lượng (35 fps) nhờ cơ chế xử lý theo lô ($N=4$) và kiến trúc luồng dữ liệu (Dataflow) đặc thù giúp xử lý hiệu quả việc phân chia nhóm kênh. Tuy nhiên, giải pháp đề xuất ($N=1$) vẫn đạt độ trễ xấp xỉ 45ms. Đây là kết quả khả quan, cung cấp khả năng phản hồi thời gian thực (Real-time) tốt hơn cho các ứng dụng đơn lẻ, loại bỏ được độ trễ tích lũy (batching latency) mà cơ chế xử lý theo lô của Eyeriss gặp phải.
\end{itemize}