\chapter{Ước lượng hiệu năng}
\label{ch:evaluation}

Chương này trình bày các kết quả thực nghiệm thu được từ mô hình ước lượng hiệu năng của kiến trúc phần cứng AI Accelerator được đề xuất trong đồ án. Nội dung đánh giá tập trung vào việc phân tích hiệu quả của thuật toán tối ưu tham số (Codegen) và khả năng xử lý của phần cứng đối với ba lớp mô hình đại diện gồm AlexNet, VGG-16 và MobileNetV1. Bên cạnh đó, nhóm thực hiện cũng tiến hành so sánh kết quả với kiến trúc Eyeriss để làm rõ các ưu điểm và hạn chế của giải pháp thiết kế.

\section{Môi trường và Phương pháp thực nghiệm}

Nhằm đánh giá để tiên liệu trước về hiệu năng của đồ án này, kiến trúc được đánh giá thông qua một mô hình ước lượng (Analytical Estimator) xây dựng bằng ngôn ngữ C++. Mô hình này hiện thực hóa các công thức toán học đã được thiết lập tại Chương 4 nhằm dự báo độ trễ và tài nguyên tiêu thụ.

Các tham số cấu hình cho quá trình mô phỏng được thiết lập dựa trên các ràng buộc phần cứng dự kiến. Cụ thể, hệ thống hoạt động ở tần số $200 \text{ MHz}$. Tốc độ của off-chip memory là 1 byte 1 cycle tương ứng tần số 200 MHz. Các giá trị đã được quantized ở dạng int8.Phạm vi đánh giá chỉ tập trung đo đạc thời gian thực thi của các lớp tích chập (Convolutional Layers), vốn là thành phần chiếm tỷ trọng tính toán lớn nhất trong mạng CNN. Chiến lược xử lý được lựa chọn là Batch Size = 1 nhằm tối ưu hóa độ trễ cho tác vụ xử lý từng ảnh đơn lẻ. Về cấu hình bộ nhớ, đồ án giả lập kiến trúc bộ nhớ tách biệt (Separate Off-chip Memory), trong đó Trọng số (Weights) và Dữ liệu (Activations) được truy xuất trên các kênh độc lập để tối ưu băng thông.

\section{Đánh giá khả năng xử lý trên AlexNet}
\label{sec:alexnet_eval}

AlexNet là một mạng nơ-ron tích chập điển hình, được đặc trưng bởi việc sử dụng các bộ lọc kích thước lớn ở các lớp đầu tiên ($11\times11$, $5\times5$). Để đánh giá hiệu năng, đồ án thực hiện chạy quá trình sinh mã (codegen) nhằm phân tích mối tương quan giữa số lượng phần tử xử lý (PE) và thời gian hoàn thành mô hình. Kết quả phân tích được thể hiện qua biểu đồ dưới đây.

\begin{figure}[H]
    \centering
    % 
    % Thay thế 'alexnet_pe_chart.png' bằng tên file ảnh thực tế của bạn
    \includegraphics[width=0.8\textwidth]{image/6/alexnet_pe_chart.png}
    \caption{Biểu đồ tương quan giữa số lượng PE và độ trễ xử lý trên AlexNet}
    \label{fig:alexnet_chart}
\end{figure}

Quan sát biểu đồ tại Hình \ref{fig:alexnet_chart}, có thể thấy điểm tối ưu nhất đạt được tại cấu hình $PE = 396$ với độ trễ (latency) là $47.04$ ms, tương đương tốc độ khung hình $21.26$ fps. Nguyên nhân là khi tăng số lượng PE, số lượng các kênh bản đồ đặc trưng đầu ra (ofmap) được tính toán song song sẽ tăng lên, đồng nghĩa với việc số lần phải tải lại toàn bộ bản đồ đặc trưng đầu vào (ifmap) giảm xuống. Với các giá trị $T_m$ tăng dần, thời gian xử lý giảm xuống rất nhanh. Tuy nhiên, khi chênh lệch giữa thời gian tải ifmap và thời gian tải ofmap không còn đáng kể, tốc độ giảm của thời gian xử lý sẽ bắt đầu bão hòa và chậm dần. Kết quả mô phỏng chi tiết với giới hạn tài nguyên 572 PEs được trình bày tại Bảng \ref{tab:alexnet_breakdown}.

\begin{table}[H]
\centering
\caption{Chi tiết hiệu năng từng lớp của AlexNet (Cập nhật)}
\label{tab:alexnet_breakdown}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
\multirow{2}{*}{\textbf{Layer}} & \multirow{2}{*}{\textbf{Filter / Channels}} & \multirow{2}{*}{\textbf{Map Size}} & \multirow{2}{*}{\textbf{PE Used}} & \multicolumn{3}{c}{\textbf{Optimized Config}} & \multirow{2}{*}{\textbf{Latency (ms)}} & \multirow{2}{*}{\textbf{Bottleneck}} \\ \cmidrule(lr){5-7}
 &  &  &  & $\mathbf{T_k}$ & $\mathbf{T_m}$ & $\mathbf{T_h}$ &  &  \\ \midrule
Conv1 & $11\times11 / 96$ & $224 \times 224$ & 396 & 3 & 12 & 1 & 8.12 & Memory \\
Conv2 & $5\times5 / 256$ & $27 \times 27$ & 180 & 3 & 12 & 1 & 13.60 & Memory \\
Conv3 & $3\times3 / 384$ & $13 \times 13$ & 108 & 3 & 12 & 1 & 7.25 & Memory \\
Conv4 & $3\times3 / 384$ & $13 \times 13$ & 108 & 3 & 12 & 1 & 10.71 & Memory \\
Conv5 & $3\times3 / 256$ & $13 \times 13$ & 108 & 3 & 12 & 1 & 7.36 & Memory \\ \midrule
\textbf{Total} & \textbf{--} & \textbf{--} & \textbf{Max 396} & \textbf{--} & \textbf{--} & \textbf{--} & \textbf{47.04} & \textbf{Memory} \\ \bottomrule
\end{tabular}%
}
\end{table}

Dựa trên kết quả thực hiện mô phỏng tại Bảng \ref{tab:alexnet_breakdown}, hệ thống đạt tổng thời gian thực thi cho mô hình AlexNet là $47,04$ ms với cấu hình phần cứng sử dụng tối đa $396$ PE. Việc áp dụng các tham số tối ưu hóa cố định $T_k = 3$ và $T_m = 12$ giúp duy trì sự ổn định trong kiến trúc, đồng thời số lượng PE huy động thực tế được điều chỉnh linh hoạt theo từng lớp để phù hợp với kích thước kernel và bản đồ đặc trưng.

Đặc điểm quan trọng nhất được ghi nhận là trạng thái \textit{Memory Bound} (nghẽn bộ nhớ) xảy ra đồng nhất trên tất cả các lớp từ Conv1 đến Conv5. Mặc dù mảng PE đã được tối ưu, tốc độ truy xuất dữ liệu từ bộ nhớ vẫn là yếu tố chi phối chính, khiến năng lực tính toán chưa được khai thác triệt để. Trong đó, lớp Conv2 chiếm tỷ trọng thời gian lớn nhất ($13,60$ ms), phản ánh áp lực truyền tải dữ liệu cực hạn khi xử lý số lượng kênh lớn. Tổng kết lại, kết quả thực nghiệm chỉ ra rằng để nâng cao hiệu năng hệ thống trong tương lai, các giải pháp cần tập trung vào việc cải thiện băng thông bộ nhớ hoặc tăng cường khả năng tái sử dụng dữ liệu (\textit{data reuse}) tại các tầng đệm trung gian.
\section{Đánh giá khả năng xử lý trên VGG-16}
\label{sec:vgg_eval}    

Để kiểm chứng khả năng chịu tải của hệ thống đối với các mạng nơ-ron tích chập có độ sâu lớn, đồ án thực hiện mô phỏng trên mô hình VGG-16. Quá trình sinh mã và phân tích sự tương quan giữa số lượng PE và thời gian hoàn thành mô hình cho kết quả như biểu đồ sau.

\begin{figure}[H]
    \centering
    % 
    % Thay thế 'vgg16_pe_chart.png' bằng tên file ảnh thực tế của bạn
    \includegraphics[width=0.8\textwidth]{image/6/vgg16_pe_chart.png}
    \caption{Biểu đồ tương quan giữa số lượng PE và độ trễ xử lý trên VGG-16}
    \label{fig:vgg16_chart}
\end{figure}

Dựa vào biểu đồ Hình \ref{fig:vgg16_chart}, điểm tối ưu nhất được xác định tại $PE = 384$ với độ trễ đạt $266.67$ ms, tương đương $3.75$ fps. Tương tự như AlexNet, việc tăng số lượng PE giúp tăng số kênh ofmap được tính toán song song và giảm số lần tải lại ifmap. Tuy nhiên, khi độ trễ giữa các lần truy cập bộ nhớ giảm xuống đến mức bão hòa, đường cong hiệu năng cũng dần đi ngang. Kết quả mô phỏng chi tiết trên tập cấu hình phần cứng tối ưu với giới hạn 390 PEs được trình bày tại Bảng \ref{tab:vgg16_breakdown}.

\begin{table}[H]
\centering
\caption{Chi tiết hiệu năng từng lớp của VGG-16}
\label{tab:vgg16_breakdown}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
\multirow{2}{*}{\textbf{Layer}} & \multirow{2}{*}{\textbf{Filter / Channels}} & \multirow{2}{*}{\textbf{Map Size}} & \multirow{2}{*}{\textbf{PE Used}} & \multicolumn{3}{c}{\textbf{Optimized Config}} & \multirow{2}{*}{\textbf{Latency (ms)}} & \multirow{2}{*}{\textbf{Bottleneck}} \\ \cmidrule(lr){5-7}
 &  &  &  & $\mathbf{T_k}$ & $\mathbf{T_m}$ & $\mathbf{T_h}$ &  &  \\ \midrule
Conv1\_1 & $3\times3 / 64$ & $224 \times 224$ & 384 & 2 & 64 & 1 & 17.07 & Memory \\
Conv1\_2 & $3\times3 / 64$ & $224 \times 224$ & 384 & 2 & 64 & 1 & 39.90 & Memory \\ \midrule
Conv2\_1 & $3\times3 / 128$ & $112 \times 112$ & 384 & 2 & 64 & 1 & 19.95 & Memory \\
Conv2\_2 & $3\times3 / 128$ & $112 \times 112$ & 384 & 2 & 64 & 1 & 31.99 & Memory \\ \midrule
Conv3\_1 & $3\times3 / 256$ & $56 \times 56$ & 384 & 2 & 64 & 1 & 16.00 & Memory \\
Conv3\_2 & $3\times3 / 256$ & $56 \times 56$ & 384 & 2 & 64 & 1 & 28.04 & Memory \\
Conv3\_3 & $3\times3 / 256$ & $56 \times 56$ & 384 & 2 & 64 & 1 & 28.04 & Memory \\ \midrule
Conv4\_1 & $3\times3 / 512$ & $28 \times 28$ & 384 & 2 & 64 & 1 & 14.02 & Memory \\
Conv4\_2 & $3\times3 / 512$ & $28 \times 28$ & 384 & 2 & 64 & 1 & 26.06 & Memory \\
Conv4\_3 & $3\times3 / 512$ & $28 \times 28$ & 384 & 2 & 64 & 1 & 26.06 & Memory \\ \midrule
Conv5\_1 & $3\times3 / 512$ & $14 \times 14$ & 384 & 2 & 64 & 1 & 6.52 & Memory \\
Conv5\_2 & $3\times3 / 512$ & $14 \times 14$ & 384 & 2 & 64 & 1 & 6.52 & Memory \\
Conv5\_3 & $3\times3 / 512$ & $14 \times 14$ & 384 & 2 & 64 & 1 & 6.52 & Memory \\ \midrule
\textbf{Total} & \textbf{--} & \textbf{--} & \textbf{Max 384} & \textbf{--} & \textbf{--} & \textbf{--} & \textbf{266.66} & \textbf{Memory} \\ \bottomrule
\end{tabular}%
}
\end{table}

Kết quả thực nghiệm trên mô hình VGG-16 ghi nhận tổng thời gian thực thi là $266,66$ ms với cấu hình phần cứng tối ưu hóa $(T_k=2, T_m=64, T_h=1)$. Hệ thống duy trì mức huy động tài nguyên ổn định tại \textbf{384 PE} cho toàn bộ 13 lớp tích chập, cho thấy sự tương thích cao giữa cấu hình phần cứng đề xuất và cấu trúc phân tầng của VGG-16.

Tuy nhiên, số liệu thống kê khẳng định toàn bộ hệ thống vận hành trong tình trạng \textit{Memory Bound} (nghẽn bộ nhớ). Độ trễ lớn nhất tập trung tại các lớp đầu như Conv1\_2 ($39,90$ ms) và các lớp có số lượng kênh lớn như khối Conv2 và Conv3, nơi sự chênh lệch chu kỳ giữa truy xuất bộ nhớ và tính toán là rõ rệt nhất. Điều này minh chứng rằng năng lực xử lý của mảng PE đang bị giới hạn bởi tốc độ cung cấp dữ liệu bản đồ đặc trưng ($ifmap$) và trọng số từ bộ nhớ ngoài. Tổng kết lại, để tối ưu hóa hiệu năng cho các kiến trúc sâu như VGG-16, hướng phát triển cần ưu tiên việc mở rộng băng thông bộ nhớ hoặc áp dụng các kỹ thuật nén mô hình để giảm thiểu khối lượng dữ liệu truyền tải, thay vì chỉ tập trung gia tăng số lượng đơn vị tính toán.

\section{Đánh giá khả năng xử lý trên MobileNet v1}
\label{sec:mobilenet_eval}

Khác với VGG-16, MobileNet v1 sử dụng kiến trúc tích chập tách biệt theo chiều sâu (Depthwise Separable Convolution) nhằm giảm khối lượng tính toán. Đồ án tiến hành chạy codegen để phân tích sự tương quan giữa số lượng PE và thời gian hoàn thành mô hình, kết quả được thể hiện trong biểu đồ sau.

\begin{figure}[H]
    \centering
    % 
    % Thay thế 'mobilenet_pe_chart.png' bằng tên file ảnh thực tế của bạn
    \includegraphics[width=0.8\textwidth]{image/6/mobilenet_pe_chart.png}
    \caption{Biểu đồ tương quan giữa số lượng PE và độ trễ xử lý trên MobileNet v1}
    \label{fig:mobilenet_chart}
\end{figure}

Dựa trên biểu đồ Hình \ref{fig:mobilenet_chart}, điểm tối ưu nhất đạt được tại $PE = 384$ với độ trễ $65.75$ ms, tương đương $15.2$ fps. Tốc độ giảm của thời gian hoàn thành khi tăng số PE chậm hơn rất nhiều so với biểu đồ của AlexNet. Lý do chính là hệ thống không vận dụng được cơ chế tích luỹ theo chiều sâu, vốn là điểm mạnh của mô hình tại các lớp Depthwise Convolution. Điều này dẫn tới thời gian xử lý không giảm đáng kể ở các lớp này, mà chủ yếu chỉ được cải thiện ở các lớp Pointwise Convolution và Standard Convolution. Kết quả mô phỏng trên tập cấu hình phần cứng tối ưu với giới hạn 385 PEs được trình bày tại Bảng \ref{tab:mobilenet_breakdown}.
\begin{table}[H]
\centering
\caption{Chi tiết hiệu năng từng lớp của MobileNet v1}
\label{tab:mobilenet_breakdown}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
\multirow{2}{*}{\textbf{Layer}} & \multirow{2}{*}{\textbf{Filter / Channels}} & \multirow{2}{*}{\textbf{Map Size}} & \multirow{2}{*}{\textbf{PE Used}} & \multicolumn{3}{c}{\textbf{Optimized Config}} & \multirow{2}{*}{\textbf{Latency (ms)}} & \multirow{2}{*}{\textbf{Bottleneck}} \\ \cmidrule(lr){5-7}
 &  &  &  & $\mathbf{T_k}$ & $\mathbf{T_m}$ & $\mathbf{T_h}$ &  &  \\ \midrule
Standard Conv (L0) & $3\times3 / 32$ & $224 \times 224$ & 96 & 1 & 32 & 1 & 3.39 & Memory \\ \midrule
Depthwise (L1) & $3\times3 / 32$ & $112 \times 112$ & 3 & 1 & 1 & 1 & 4.02 & Memory \\
Pointwise (L2) & $1\times1 / 64$ & $112 \times 112$ & 64 & 1 & 64 & 1 & 6.02 & Memory \\ \midrule
Depthwise (L3) & $3\times3 / 64$ & $56 \times 56$ & 3 & 1 & 1 & 23 & 6.70 & Memory \\
Pointwise (L4) & $1\times1 / 128$ & $56 \times 56$ & 128 & 1 & 128 & 1 & 3.01 & Memory \\ \midrule
Depthwise (L5) & $3\times3 / 128$ & $56 \times 56$ & 3 & 1 & 1 & 1 & 4.02 & Memory \\
Pointwise (L6) & $1\times1 / 128$ & $56 \times 56$ & 128 & 1 & 128 & 1 & 4.01 & Memory \\ \midrule
Depthwise (L7) & $3\times3 / 128$ & $28 \times 28$ & 3 & 1 & 1 & 56 & 2.57 & Memory \\
Pointwise (L8) & $1\times1 / 256$ & $28 \times 28$ & 128 & 1 & 128 & 1 & 2.01 & Memory \\ \midrule
Depthwise (L9) & $3\times3 / 256$ & $28 \times 28$ & 3 & 1 & 1 & 1 & 2.01 & Memory \\
Pointwise (L10) & $1\times1 / 256$ & $28 \times 28$ & 128 & 1 & 128 & 1 & 3.01 & Memory \\ \midrule
Depthwise (L11) & $3\times3 / 256$ & $14 \times 14$ & 3 & 1 & 1 & 28 & 1.27 & Memory \\
Pointwise (L12) & $1\times1 / 512$ & $14 \times 14$ & 128 & 1 & 128 & 1 & 1.51 & Memory \\ \midrule
Avg. DW (L13-25 odd) & $3\times3 / 512$ & $14 \times 14$ & 3 & 1 & 1 & 1$^*$ & 0.88$^\dagger$ & Memory \\
Avg. PW (L14-26 even) & $1\times1 / 512$ & $14 \times 14$ & 128 & 1 & 128 & 1 & 2.21$^\dagger$ & Memory \\ \midrule
\textbf{Total} & \textbf{--} & \textbf{--} & \textbf{Max 128} & \textbf{--} & \textbf{--} & \textbf{--} & \textbf{65.75} & \textbf{Memory} \\ \bottomrule
\multicolumn{9}{l}{\small $^*$ Giá trị $T_h$ thay đổi tùy lớp (1-14). $^\dagger$ Giá trị trung bình của các lớp lặp lại trong khối Conv5.}
\end{tabular}%
}
\end{table}
Dựa trên kết quả tại Bảng \ref{tab:mobilenet_breakdown}, mô hình MobileNet v1 đạt tổng thời gian thực thi là $65,75$ ms với mảng PE huy động tối đa $128$ đơn vị. Đặc điểm quan trọng nhất là trạng thái \textit{Memory Bound} (nghẽn bộ nhớ) xảy ra đồng nhất trên $100\%$ các lớp, minh chứng rằng băng thông truy xuất dữ liệu đang là điểm nghẽn chính cản trở năng lực tính toán của hệ thống bất kể loại hình tích chập nào.

Trong các lớp Pointwise ($1 \times 1$), hệ thống tận dụng tối đa cấu hình song song $T_m = 128$ để xử lý số lượng kênh lớn, dẫn đến việc huy động tài nguyên phần cứng ở mức cao nhất. Tuy nhiên, các lớp này vẫn chiếm tỷ trọng thời gian thực thi lớn (từ $1,25$ ms đến $6,02$ ms) do khối lượng dữ liệu bản đồ đặc trưng cần luân chuyển quá lớn. Ngược lại, các lớp Depthwise ($3 \times 3$) bộc lộ sự hạn chế về hiệu suất sử dụng tài nguyên khi chỉ huy động được $3$ PE mỗi chu kỳ do đặc thù tính toán đơn kênh ($T_m = 1$). Mặc dù độ trễ của các lớp Depthwise được duy trì ở mức thấp (tối thiểu $0,50$ ms), nhưng hiệu suất sử dụng phần cứng cực thấp (chỉ khoảng $2,3\%$ so với mức tối đa) đặt ra yêu cầu cấp thiết về việc cải tiến kiến trúc mảng PE để thích ứng tốt hơn với các khối tích chập tách rời.

Tổng kết lại, kết quả thực nghiệm cho thấy MobileNet v1 chịu tác động kép từ giới hạn băng thông bộ nhớ và sự không tương thích giữa cấu trúc lớp Depthwise với mảng PE song song hóa cao. Các giải pháp tiếp theo cần tập trung vào việc tối ưu hóa bộ đệm cho lớp Pointwise và tái cấu trúc sơ đồ tính toán cho lớp Depthwise để giải tỏa điểm nghẽn hiện tại.
\section{So sánh với các Nghiên cứu liên quan}
\label{sec:comparison}

Để đánh giá khách quan hiệu quả của kiến trúc đề xuất, chúng tôi thực hiện so sánh đối chứng với kết quả đo đạc thực tế trên silicon của chip gia tốc Eyeriss [Chen et al., ISSCC 2016]. Các thông số tham chiếu của Eyeriss được lấy từ cấu hình tối ưu với Batch Size $N=4$ cho AlexNet và $N=3$ cho VGG16.Nhằm đảm bảo tính tương đồng trong điều kiện thử nghiệm, kiến trúc đề xuất được cấu hình với 165 PE (xấp xỉ số lượng PE của Eyeriss), đồng thời sử dụng mô hình AlexNet với Grouped Convolution tại các lớp conv2, conv4 và conv5 đúng theo nguyên bản. Bên cạnh đó, các tham số hệ thống cũng được đồng bộ hóa với thiết kế Eyeriss: băng thông bộ nhớ ngoài (off-chip memory) giới hạn ở mức 480MB/s và độ chính xác tính toán là 16-bit fixed-point. Kết quả so sánh chi tiết được trình bày tại Bảng \ref{tab:comparison_eyeriss}.

\begin{table}[H]
\centering
\caption{So sánh hiệu năng xử lý Convolution trên AlexNet và VGG16}
\label{tab:comparison_eyeriss}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|c|c|}
\hline
\textbf{Thông số} & \textbf{Đề xuất (Ours)} & \textbf{Eyeriss [Chen et al.]} \\ \hline
Số lượng PE & 165 (AlexNet) - 162 (VGG16) & 168 \\ \hline
Kiến trúc bộ nhớ & Separate Off-chip Memory & Shared DRAM \\ \hline
Chiến lược xử lý & \textbf{Batch Size = 1} (Real-time) & \textbf{Batch Size = 3-4} (Throughput) \\ \hline
\textbf{AlexNet (Latency)} & 71.24 ms (14.03 fps) & \textbf{28.57 ms}* (35.0 fps) \\ \hline
\textbf{VGG16 (Latency)} & \textbf{555.8 ms} (1.80 fps) & 1428.57 ms** (0.7 fps) \\ \hline
\end{tabular}%
}
\vspace{0.2cm}
\footnotesize{
\textit{*AlexNet Eyeriss: Tính trung bình trên Batch=4 ($N=4$).} \\
\textit{**VGG16 Eyeriss: Tính trung bình trên Batch=3 ($N=3$).}
}
\end{table}


Dựa trên kết quả đối sánh chi tiết tại Bảng \ref{tab:comparison_eyeriss}, kiến trúc đề xuất thể hiện những ưu thế chiến lược về khả năng xử lý thời gian thực và hiệu quả quản lý băng thông so với kiến trúc Eyeriss. Sự khác biệt rõ rệt nhất được ghi nhận tại mô hình VGG16, nơi giải pháp của nhóm nghiên cứu đạt hiệu năng vượt trội với độ trễ thấp hơn khoảng \textbf{2,59 lần} (chỉ $555,8$ ms so với $1428,57$ ms của Eyeriss). Kết quả đột phá này đạt được nhờ việc áp dụng kiến trúc bộ nhớ tách biệt (\textit{Separate Off-chip Memory}), giúp mở rộng băng thông truy xuất dữ liệu độc lập cho trọng số và bản đồ đặc trưng. Cách tiếp cận này giúp giải tỏa triệt để hiện tượng nghẽn mạch bộ nhớ (\textit{Memory Bottleneck}) — một hạn chế cố hữu của các kiến trúc sử dụng bộ nhớ chia sẻ (\textit{Shared DRAM}) khi phải đối mặt với khối lượng dữ liệu khổng lồ của các mạng nơ-ron sâu như VGG16.

Đối với mô hình AlexNet, mặc dù Eyeriss đạt thông lượng cao hơn ($35,0$ fps) nhờ tận dụng cơ chế xử lý theo lô (\textit{Batch Size = 4}), kiến trúc đề xuất vẫn khẳng định được giá trị thực tiễn với độ trễ phản hồi đơn lẻ đạt $71,24$ ms tại $N=1$. Trong khi Eyeriss ưu tiên tối ưu hóa hiệu suất tổng thể (\textit{Throughput}) dựa trên việc tích lũy dữ liệu, giải pháp của nhóm hướng tới các ứng dụng thực tế yêu cầu phản hồi tức thời (\textit{Real-time}). Việc loại bỏ độ trễ tích lũy (\textit{Batching Latency}) giúp hệ thống đề xuất trở nên phù hợp hơn cho các bài toán biên (\textit{Edge computing}), nơi tính thời điểm của thông tin quan trọng hơn lưu lượng xử lý tổng thể. Tổng kết lại, sự kết hợp giữa mảng PE linh hoạt và kiến trúc bộ nhớ tối ưu đã giúp hệ thống đề xuất đạt được sự cân bằng hiệu quả giữa năng lực tính toán và tốc độ phản hồi trên các cấu trúc mạng có độ phức tạp khác nhau.